# services/smart_visualization_service.py - ì‹¤ì œ ë‚´ìš© ë°˜ì˜ ë²„ì „
from langchain_core.prompts import ChatPromptTemplate
from utils.llm_factory import create_llm
import json
import re
from typing import List, Dict


class SmartVisualizationService:
    def __init__(self):
        self.llm = create_llm()
        self._setup_content_aware_prompts()

    def _setup_content_aware_prompts(self):
        """ì‹¤ì œ ì˜ìƒ ë‚´ìš©ì„ ë°˜ì˜í•˜ëŠ” í”„ë¡¬í”„íŠ¸"""

        self.generation_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ë‹¹ì‹ ì€ YouTube ì˜ìƒ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì •í™•í•œ ì‹œê°í™”ë¥¼ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ğŸ”‘ í•µì‹¬ ì›ì¹™:
1. ë°˜ë“œì‹œ ì£¼ì–´ì§„ ì˜ìƒì˜ ì‹¤ì œ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
2. ë‹¤ë¥¸ ì£¼ì œì˜ ë‚´ìš©ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”  
3. ì˜ìƒì— ë‚˜ì˜¤ì§€ ì•Šì€ ì •ë³´ëŠ” ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”
4. êµ¬ì²´ì ì´ê³  ì‹¤ì œì ì¸ ì •ë³´ë§Œ í¬í•¨í•˜ì„¸ìš”

âš ï¸ ì ˆëŒ€ ê¸ˆì§€:
- í…œí”Œë¦¿ í…ìŠ¤íŠ¸ ("ì„¸ë¶€1", "í•­ëª©1" ë“±)
- ë‹¤ë¥¸ ì£¼ì œ ë‚´ìš© í˜¼ì…
- ì¼ë°˜ë¡ ì  í‘œí˜„ ("í•µì‹¬ ì£¼ì œ" ë“±)
- ì˜ìƒê³¼ ê´€ë ¨ì—†ëŠ” ë‚´ìš©

âœ… ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ:
- ì˜ìƒì˜ í•µì‹¬ ì£¼ì œë¥¼ ì •í™•íˆ íŒŒì•…
- ì˜ìƒì—ì„œ ì–¸ê¸‰ëœ êµ¬ì²´ì  ì •ë³´ë§Œ ì‚¬ìš©
- í•™ìŠµìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ êµ¬ì¡°ë¡œ ì •ë¦¬

í˜„ì¬ ì˜ìƒ ì£¼ì œ: {topic}
ìš”ì²­ ì‹œê°í™”: {viz_type}

ì˜ìƒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {viz_type} ì‹œê°í™”ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.
            """),
            ("human", "ì˜ìƒ ì£¼ì œ: {topic}\n\nì˜ìƒ ë‚´ìš©:\n{content}\n\níŠ¹ë³„ ì§€ì‹œ: ìœ„ ì˜ìƒ ë‚´ìš©ì—ì„œë§Œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ {viz_type} ì‹œê°í™”ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        ])

    async def analyze_and_generate_visualizations(self, caption: str, report_text: str) -> List[Dict]:
        """ì‹¤ì œ ì˜ìƒ ë‚´ìš© ê¸°ë°˜ ì‹œê°í™” ìƒì„±"""

        # ğŸ”‘ ì‹¤ì œ ì£¼ì œ ì¶”ì¶œ (í•˜ë“œì½”ë”© ë°©ì§€)
        actual_topic = self._extract_actual_topic(report_text, caption)
        print(f"ğŸ¯ ì‹¤ì œ ì˜ìƒ ì£¼ì œ: {actual_topic}")

        # ì‹¤ì œ ë‚´ìš© ê¸°ë°˜ ì„¹ì…˜ ë¶„í• 
        sections = self._analyze_content_sections(report_text, caption)

        visualizations = []
        position = 0

        # ì œëª© ì„¹ì…˜
        visualizations.append({
            "type": "paragraph",
            "title": "",
            "content": f"ì œëª©: {actual_topic}",
            "position": position
        })
        position += 1

        for section in sections:
            # í…ìŠ¤íŠ¸ ì„¹ì…˜
            visualizations.append({
                "type": "paragraph",
                "title": section["title"],
                "content": section["content"],
                "position": position
            })
            position += 1

            # ğŸ”‘ ì‹¤ì œ ë‚´ìš© ê¸°ë°˜ ì‹œê°í™” ìƒì„±
            viz_type = self._determine_appropriate_visualization(section, actual_topic)
            if viz_type:
                viz_data = await self._generate_content_specific_visualization(
                    viz_type, actual_topic, section, caption
                )
                if viz_data and self._validate_content_accuracy(viz_data, actual_topic):
                    viz_data["position"] = position
                    visualizations.append(viz_data)
                    position += 1
                    print(f"âœ… {actual_topic} ê¸°ë°˜ {viz_type} ìƒì„± ì™„ë£Œ")
                else:
                    print(f"âŒ {viz_type} ë‚´ìš© ì •í™•ì„± ê²€ì¦ ì‹¤íŒ¨")

        return visualizations

    def _extract_actual_topic(self, report_text: str, caption: str) -> str:
        """ì‹¤ì œ ì˜ìƒ ì£¼ì œ ì •í™•íˆ ì¶”ì¶œ"""

        # ì œëª©ì—ì„œ ì¶”ì¶œ ì‹œë„
        lines = report_text.split('\n')
        for line in lines:
            if 'ì œëª©:' in line:
                topic = line.replace('ì œëª©:', '').strip()
                if len(topic) > 5:  # ì˜ë¯¸ìˆëŠ” ì œëª©ì¸ì§€ í™•ì¸
                    return topic

        # ìë§‰ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        caption_words = re.findall(r'[ê°€-í£]{2,}', caption[:500])  # ì²˜ìŒ 500ìì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        word_count = {}
        for word in caption_words:
            if len(word) >= 3:  # 3ê¸€ì ì´ìƒ ë‹¨ì–´ë§Œ
                word_count[word] = word_count.get(word, 0) + 1

        # ê°€ì¥ ë¹ˆë²ˆí•œ ë‹¨ì–´ë“¤ë¡œ ì£¼ì œ êµ¬ì„±
        if word_count:
            top_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)[:3]
            topic_keywords = [word for word, count in top_words if count >= 2]
            if topic_keywords:
                return ' '.join(topic_keywords[:2])  # ìƒìœ„ 2ê°œ í‚¤ì›Œë“œ ì¡°í•©

        # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ë³´ê³ ì„œ ì²« ë¬¸ì¥
        first_sentence = report_text.split('.')[0].strip()
        if len(first_sentence) < 100:
            return first_sentence

        return "ì˜ìƒ ë‚´ìš© ë¶„ì„"

    def _analyze_content_sections(self, report_text: str, caption: str) -> List[Dict]:
        """ë‚´ìš© ê¸°ë°˜ ì„¹ì…˜ ë¶„ì„"""
        sections = []

        # ë³´ê³ ì„œë¥¼ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„í• 
        paragraphs = re.split(r'\n\s*\n|\d+\.\s+', report_text)

        current_section = {"title": "ìš”ì•½", "content": ""}

        for para in paragraphs:
            para = para.strip()
            if not para:
                continue

            # ì„¹ì…˜ ì œëª© ê°ì§€ (ì¢€ ë” ì •í™•í•˜ê²Œ)
            if (len(para) < 50 and
                    any(keyword in para for keyword in ['ìš”ì•½', 'ì£¼ìš”', 'ë‚´ìš©', 'ê³¼ì •', 'ë°©ë²•', 'ê²°ë¡ ', 'ì˜ì˜', 'ì›ë¦¬', 'ê³µì‹'])):

                if current_section["content"]:
                    sections.append(current_section)

                # ì œëª©ì—ì„œ ì½œë¡  ì œê±°í•˜ê³  ì •ë¦¬
                title = para.replace(':', '').strip()
                current_section = {"title": title, "content": ""}
            else:
                current_section["content"] += para + " "

        if current_section["content"]:
            sections.append(current_section)

        # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
        unique_sections = []
        seen_content = set()

        for section in sections:
            content_key = section["content"][:100]  # ì²˜ìŒ 100ìë¡œ ì¤‘ë³µ ì²´í¬
            if content_key not in seen_content and len(section["content"]) > 20:
                seen_content.add(content_key)
                unique_sections.append(section)

        return unique_sections[:4]  # ìµœëŒ€ 4ê°œ ì„¹ì…˜

    def _determine_appropriate_visualization(self, section: Dict, topic: str) -> str:
        """ì‹¤ì œ ë‚´ìš©ì— ì í•©í•œ ì‹œê°í™” íƒ€ì… ê²°ì •"""
        content = section["content"].lower()
        title = section["title"].lower()
        topic_lower = topic.lower()

        # ì£¼ì œë³„ íŠ¹í™” ì‹œê°í™” ì„ íƒ
        if any(word in topic_lower for word in ['ê³µì‹', 'ìˆ˜í•™', 'ê³„ì‚°', 'ì•Œê³ ë¦¬ì¦˜']):
            if any(word in content for word in ['ë‹¨ê³„', 'ê³¼ì •', 'ë°©ë²•', 'ì ˆì°¨']):
                return "flowchart"
            elif any(word in content for word in ['êµ¬ì„±', 'ìš”ì†Œ', 'ì›ë¦¬']):
                return "mindmap"

        elif any(word in topic_lower for word in ['ì—­ì‚¬', 'ë°œì „', 'ë³€í™”']):
            return "timeline"

        elif any(word in content for word in ['ë¹„êµ', 'ì°¨ì´', 'ì¢…ë¥˜', 'vs']):
            return "comparison"

        elif any(word in content for word in ['êµ¬ì¡°', 'ë¶„ë¥˜', 'ê³„ì¸µ', 'ì²´ê³„']):
            return "tree"

        elif any(word in content for word in ['ê°œë…', 'ê´€ê³„', 'ì—°ê²°', 'ìš”ì†Œ']):
            return "mindmap"

        elif any(word in content for word in ['ê³¼ì •', 'ë‹¨ê³„', 'ë°©ë²•', 'ì ˆì°¨', 'ìˆœì„œ']):
            return "flowchart"

        return None

    async def _generate_content_specific_visualization(self, viz_type: str, topic: str, section: Dict,
                                                       caption: str) -> Dict:
        """ì‹¤ì œ ë‚´ìš©ì— íŠ¹í™”ëœ ì‹œê°í™” ìƒì„±"""

        try:
            # ğŸ”‘ ì‹¤ì œ ì˜ìƒ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ë„ë¡ ì»¨í…ìŠ¤íŠ¸ ì œí•œ
            relevant_caption = self._extract_relevant_content(caption, section["content"])

            messages = self.generation_prompt.format_messages(
                viz_type=viz_type,
                topic=topic,
                content=f"ì„¹ì…˜: {section['title']}\në‚´ìš©: {section['content']}\nê´€ë ¨ ìë§‰: {relevant_caption}"
            )

            response = self.llm.invoke(messages)

            if response and response.content:
                content_text = response.content.strip()

                # JSON ì¶”ì¶œ
                if "```json" in content_text:
                    start = content_text.find("```json") + 7
                    end = content_text.find("```", start)
                    if end > start:
                        content_text = content_text[start:end].strip()

                viz_data = json.loads(content_text)

                # ğŸ”‘ ë‚´ìš© ê²€ì¦ ë° êµì •
                viz_data = self._correct_content_mismatch(viz_data, topic, section)

                return viz_data

        except Exception as e:
            print(f"âš ï¸ {viz_type} ìƒì„± ì‹¤íŒ¨: {e}")

        # ì‹¤íŒ¨ ì‹œ ì‹¤ì œ ë‚´ìš© ê¸°ë°˜ ê¸°ë³¸ ì‹œê°í™”
        return self._create_topic_specific_fallback(viz_type, topic, section)

    def _extract_relevant_content(self, caption: str, section_content: str) -> str:
        """ì„¹ì…˜ê³¼ ê´€ë ¨ëœ ìë§‰ ë¶€ë¶„ë§Œ ì¶”ì¶œ"""

        # ì„¹ì…˜ì˜ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        section_keywords = re.findall(r'[ê°€-í£]{3,}', section_content)

        # ìë§‰ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
        sentences = re.split(r'[.!?]\s+', caption)

        relevant_sentences = []
        for sentence in sentences:
            # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ë§Œ ì„ ë³„
            if any(keyword in sentence for keyword in section_keywords[:5]):
                relevant_sentences.append(sentence)

        return ' '.join(relevant_sentences[:3])  # ìµœëŒ€ 3ë¬¸ì¥

    def _correct_content_mismatch(self, viz_data: Dict, topic: str, section: Dict) -> Dict:
        """ë‚´ìš© ë¶ˆì¼ì¹˜ êµì •"""

        # ì£¼ì œ ë¶ˆì¼ì¹˜ ê°ì§€ ë° êµì •
        data = viz_data.get("data", {})

        if viz_data.get("type") == "mindmap":
            # ì¤‘ì‹¬ ì£¼ì œ êµì •
            center = data.get("center", "")
            if "ì¤‘ë ¥íŒŒ" in center and "ì¤‘ë ¥íŒŒ" not in topic:
                # ì‹¤ì œ ì£¼ì œë¡œ êµì²´
                main_keyword = self._extract_main_keyword(topic)
                data["center"] = main_keyword

            # ë¸Œëœì¹˜ ë‚´ìš© êµì •
            branches = data.get("branches", [])
            section_keywords = re.findall(r'[ê°€-í£]{3,}', section["content"])

            for i, branch in enumerate(branches):
                # ì„¹ì…˜ ë‚´ìš©ê³¼ ê´€ë ¨ëœ í‚¤ì›Œë“œë¡œ êµì²´
                if i < len(section_keywords):
                    branch["label"] = section_keywords[i]

                # í•˜ìœ„ í•­ëª©ë„ ê´€ë ¨ ë‚´ìš©ìœ¼ë¡œ êµì²´
                children = branch.get("children", [])
                relevant_terms = self._extract_related_terms(section["content"], branch["label"])
                if relevant_terms:
                    branch["children"] = relevant_terms[:3]

        elif viz_data.get("type") == "flowchart":
            # í”Œë¡œìš°ì°¨íŠ¸ ë…¸ë“œ ë‚´ìš© êµì •
            nodes = data.get("nodes", [])
            steps = self._extract_process_steps(section["content"])

            if steps and len(steps) >= 3:
                for i, node in enumerate(nodes):
                    if i < len(steps) and node.get("type") == "process":
                        node["label"] = steps[i]

        viz_data["data"] = data
        return viz_data

    def _extract_main_keyword(self, topic: str) -> str:
        """ì£¼ì œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        words = re.findall(r'[ê°€-í£]{2,}', topic)
        # ê°€ì¥ ê¸´ ë‹¨ì–´ ë˜ëŠ” ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ì„ íƒ
        meaningful_words = [w for w in words if len(w) >= 3]
        return meaningful_words[0] if meaningful_words else words[0] if words else topic

    def _extract_related_terms(self, content: str, main_term: str) -> List[str]:
        """ë©”ì¸ ìš©ì–´ì™€ ê´€ë ¨ëœ í•˜ìœ„ ìš©ì–´ë“¤ ì¶”ì¶œ"""
        sentences = content.split('.')
        related_terms = []

        for sentence in sentences:
            if main_term in sentence:
                # ë¬¸ì¥ì—ì„œ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë“¤ ì¶”ì¶œ
                words = re.findall(r'[ê°€-í£]{3,}', sentence)
                for word in words:
                    if word != main_term and word not in related_terms:
                        related_terms.append(word)

        return related_terms[:3] if related_terms else [f"{main_term} íŠ¹ì„±", f"{main_term} í™œìš©", f"{main_term} ì›ë¦¬"]

    def _extract_process_steps(self, content: str) -> List[str]:
        """ë‚´ìš©ì—ì„œ ì‹¤ì œ ê³¼ì • ë‹¨ê³„ë“¤ ì¶”ì¶œ"""
        # ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ ë‹¨ê³„ ì°¾ê¸°
        numbered_steps = re.findall(r'\d+[ë‹¨ê³„\.]\s*([^.]+)', content)
        if numbered_steps:
            return numbered_steps

        # "ë¨¼ì €", "ë‹¤ìŒ", "ë§ˆì§€ë§‰" ë“±ì˜ ìˆœì„œ í‘œí˜„ ì°¾ê¸°
        sequence_patterns = [
            r'ë¨¼ì €[,\s]*([^.]+)',
            r'ë‹¤ìŒ[,\s]*([^.]+)',
            r'ê·¸\s*ë‹¤ìŒ[,\s]*([^.]+)',
            r'ë§ˆì§€ë§‰[,\s]*([^.]+)'
        ]

        steps = []
        for pattern in sequence_patterns:
            matches = re.findall(pattern, content)
            steps.extend(matches)

        return steps[:4] if steps else []

    def _validate_content_accuracy(self, viz_data: Dict, topic: str) -> bool:
        """ë‚´ìš© ì •í™•ì„± ê²€ì¦"""

        # ì£¼ì œ ì¼ì¹˜ì„± ê²€ì¦
        data_str = str(viz_data).lower()
        topic_lower = topic.lower()

        # ì£¼ì œì™€ ì™„ì „íˆ ë‹¤ë¥¸ ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
        conflicting_topics = ["ì¤‘ë ¥íŒŒ", "ë¸”ë™í™€", "ì•„ì¸ìŠˆíƒ€ì¸"]
        topic_keywords = re.findall(r'[ê°€-í£]{2,}', topic_lower)

        for conflict in conflicting_topics:
            if conflict in data_str and not any(keyword in conflict for keyword in topic_keywords):
                print(f"âš ï¸ ì£¼ì œ ë¶ˆì¼ì¹˜ ê°ì§€: {conflict} in {topic}")
                return False

        return True

    def _create_topic_specific_fallback(self, viz_type: str, topic: str, section: Dict) -> Dict:
        """ì£¼ì œë³„ ë§ì¶¤ ê¸°ë³¸ ì‹œê°í™”"""

        main_keyword = self._extract_main_keyword(topic)
        section_keywords = re.findall(r'[ê°€-í£]{3,}', section["content"])[:3]

        if viz_type == "mindmap":
            return {
                "type": "mindmap",
                "title": f"{topic} í•µì‹¬ ê°œë…",
                "data": {
                    "center": main_keyword,
                    "branches": [
                        {
                            "label": section_keywords[0] if len(section_keywords) > 0 else "ê¸°ë³¸ ê°œë…",
                            "children": [f"{main_keyword} ì •ì˜", f"{main_keyword} íŠ¹ì§•", f"{main_keyword} ì¤‘ìš”ì„±"]
                        },
                        {
                            "label": section_keywords[1] if len(section_keywords) > 1 else "ì‘ìš© ë¶„ì•¼",
                            "children": [f"{main_keyword} í™œìš©", f"{main_keyword} ì¥ì ", f"{main_keyword} íš¨ê³¼"]
                        },
                        {
                            "label": section_keywords[2] if len(section_keywords) > 2 else "ê´€ë ¨ ê¸°ìˆ ",
                            "children": [f"{main_keyword} ì›ë¦¬", f"{main_keyword} ë°©ë²•", f"{main_keyword} ê¸°ìˆ "]
                        }
                    ]
                }
            }

        elif viz_type == "flowchart":
            steps = self._extract_process_steps(section["content"])
            if not steps:
                steps = [f"{main_keyword} ì‹œì‘", f"{main_keyword} ì§„í–‰", f"{main_keyword} ì™„ë£Œ"]

            return {
                "type": "flowchart",
                "title": f"{section['title']} ê³¼ì •",
                "data": {
                    "nodes": [
                        {"id": "1", "label": steps[0] if len(steps) > 0 else "ì‹œì‘", "type": "start"},
                        {"id": "2", "label": steps[1] if len(steps) > 1 else f"{main_keyword} ì ìš©", "type": "process"},
                        {"id": "3", "label": steps[2] if len(steps) > 2 else f"{main_keyword} ê²€ì¦", "type": "process"},
                        {"id": "4", "label": steps[3] if len(steps) > 3 else "ì™„ë£Œ", "type": "end"}
                    ],
                    "edges": [
                        {"from": "1", "to": "2"},
                        {"from": "2", "to": "3"},
                        {"from": "3", "to": "4"}
                    ]
                }
            }

        return {
            "type": "paragraph",
            "title": section["title"],
            "content": section["content"]
        }