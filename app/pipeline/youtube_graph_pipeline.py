import os
import requests
import json
from typing import TypedDict, List, Dict, Any, Optional
import boto3
import time
from dotenv import load_dotenv
from langgraph.graph import StateGraph
from langchain_core.runnables import Runnable, RunnableLambda
from langchain_aws import ChatBedrock
from langchain_core.prompts import ChatPromptTemplate
from langsmith.run_helpers import traceable
import logging
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ========== 1. ìƒíƒœ ì •ì˜ ==========
class ImprovedGraphState(TypedDict):
    youtube_url: str
    caption: str
    report_text: str
    visualization_requests: List[Dict]
    generated_visualizations: List[Dict]
    final_output: Dict

# ========== 2. í™˜ê²½ ë³€ìˆ˜ ë¡œë”© ==========
load_dotenv()
VIDCAP_API_KEY = os.getenv("VIDCAP_API_KEY")
AWS_REGION = os.getenv("AWS_REGION")
BEDROCK_MODEL_ID = os.getenv("BEDROCK_MODEL_ID")

# ========== 3. ìë§‰ ì¶”ì¶œ ë„êµ¬ ==========
def extract_youtube_caption_tool(youtube_url: str) -> str:
    """YouTube ìë§‰ ì¶”ì¶œ"""
    try:
        api_url = "https://vidcap.xyz/api/v1/youtube/caption"
        params = {"url": youtube_url, "locale": "ko"}
        headers = {"Authorization": f"Bearer {VIDCAP_API_KEY}"}
        response = requests.get(api_url, params=params, headers=headers)
        response.raise_for_status()
        return response.json().get("data", {}).get("content", "")
    except Exception as e:
        logger.error(f"ìë§‰ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return f"[ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}]"

# ========== 4. LLM ì„¤ì • ==========
llm = ChatBedrock(
    client=boto3.client("bedrock-runtime", region_name=AWS_REGION),
    model_id=BEDROCK_MODEL_ID,
    model_kwargs={"temperature": 0.0, "max_tokens": 8000}
)

# ========== 5. ë³´ê³ ì„œ ìƒì„± í”„ë¡¬í”„íŠ¸ ==========
structure_prompt = ChatPromptTemplate.from_messages([
    ("system", """ë„ˆëŠ” ìœ íŠœë¸Œ ìë§‰ì„ ìƒì„¸í•˜ê³  ì™„ì „í•œ ë³´ê³ ì„œë¡œ ì¬ì‘ì„±í•˜ëŠ” AIì•¼.

## í•µì‹¬ ì›ì¹™
- **ì™„ì „ì„±**: ë…ìê°€ ì˜ìƒì„ ë³´ì§€ ì•Šì•„ë„ 100% ì´í•´ ê°€ëŠ¥í•´ì•¼ í•¨
- **êµ¬ì²´ì„±**: ì¤‘ìš”í•œ ìˆ˜ì¹˜, ì‚¬ë¡€, ì¸ìš©êµ¬ëŠ” ë°˜ë“œì‹œ í¬í•¨
- **ìƒì„¸ì„±**: ê° ì„¹ì…˜ì€ ì¶©ë¶„íˆ ìì„¸í•˜ê²Œ ì„¤ëª… (ìµœì†Œ 500ì ì´ìƒ)

## ë³´ê³ ì„œ ì‘ì„± ì§€ì¹¨

#### 1.1 í‘œì§€ ì •ë³´
- ë³´ê³ ì„œ ì œëª©: "[ì˜ìƒ ì œëª©] ë¶„ì„ ë³´ê³ ì„œ"

#### 1.2 ëª©ì°¨
- ê° ì„¹ì…˜ë³„ í˜ì´ì§€ ë²ˆí˜¸ í¬í•¨
- ìµœì†Œ 5ê°œ ì´ìƒì˜ ì£¼ìš” ì„¹ì…˜ êµ¬ì„±

#### 1.3 í•„ìˆ˜ ì„¹ì…˜ êµ¬ì„±
1. **ê°œìš” (Executive Summary)**
- ì˜ìƒì˜ í•µì‹¬ ë‚´ìš© ìš”ì•½ (200-300ì)
- ì£¼ìš” í‚¤ì›Œë“œ ë° í•µì‹¬ ë©”ì‹œì§€

2. **ì£¼ìš” ë‚´ìš© ë¶„ì„**
- ìµœì†Œ 3ê°œ ì´ìƒì˜ ì„¸ë¶€ ë¬¸ë‹¨
- ê° ë¬¸ë‹¨ë‹¹ 500ì ì´ìƒ
- ë¬¸ë‹¨ êµ¬ì¡°: ì†Œì œëª© + ìš”ì•½ + ìƒì„¸ ì„¤ëª…

3. **í•µì‹¬ ì¸ì‚¬ì´íŠ¸**
- ì˜ìƒì—ì„œ ë„ì¶œë˜ëŠ” ì£¼ìš” ì‹œì‚¬ì 
- ì‹¤ë¬´ì /í•™ìˆ ì  í•¨ì˜

4. **ê²°ë¡  ë° ì œì–¸**
- ì „ì²´ ë‚´ìš© ì¢…í•©
- í–¥í›„ ë°©í–¥ì„± ë˜ëŠ” ì‘ìš© ê°€ëŠ¥ì„±

5. **ë¶€ë¡**
- ì£¼ìš” ì¸ìš©êµ¬
- ì°¸ê³  ìë£Œ (í•´ë‹¹ ì‹œ)

### 2. ì‘ì„± ê¸°ì¤€

#### 2.1 ë¬¸ì²´ ë° í˜•ì‹
- **ì„œìˆ í˜• ë¬¸ì¥**: êµ¬ì–´ì²´ë¥¼ ë¬¸ì–´ì²´ë¡œ ì™„ì „ ë³€í™˜
- **ê°ê´€ì  ì–´ì¡°**: 3ì¸ì¹­ ê´€ì ì—ì„œ ì„œìˆ 
- **ì „ë¬¸ì  í‘œí˜„**: í•™ìˆ ì /ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´ í™œìš©
- **ë…¼ë¦¬ì  ì—°ê²°**: ë¬¸ì¥ ê°„ ì—°ê²°ê³ ë¦¬ ëª…í™•í™”

#### 2.2 ë‚´ìš© êµ¬ì„±
- **êµ¬ì²´ì  ì •ë³´ í•„ìˆ˜ í¬í•¨**:
  - ì •í™•í•œ ìˆ˜ì¹˜ (ë…„ë„, í¬ê¸°, ë¹„ìœ¨ ë“±)
  - êµ¬ì²´ì  ì‚¬ë¡€ì™€ ì˜ˆì‹œ
  - ì¤‘ìš”í•œ ì¸ìš©êµ¬ë‚˜ ë°œì–¸
  - íšŒì‚¬ëª…, ì œí’ˆëª…, ê¸°ìˆ ëª… ë“±

- **ê° ì„¹ì…˜ ìµœì†Œ 500ì ì´ìƒ**:
  - ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹Œ ìƒì„¸í•œ ì„¤ëª…
  - ë°°ê²½ ì •ë³´ì™€ ë§¥ë½ ì œê³µ
  - ì›ì¸ê³¼ ê²°ê³¼, ì˜í–¥ ë¶„ì„

- **ì™„ì „í•œ ì´í•´ë¥¼ ìœ„í•œ ì„œìˆ **:
  - ì „ë¬¸ ìš©ì–´ëŠ” ë°˜ë“œì‹œ ì„¤ëª… ì¶”ê°€
  - ë³µì¡í•œ ê°œë…ì€ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…
  - ë…ìê°€ ì¶”ê°€ ê²€ìƒ‰ ì—†ì´ë„ ì´í•´ ê°€ëŠ¥í•˜ë„ë¡

#### 2.3 í’ˆì§ˆ ê¸°ì¤€
- **ì¼ê´€ì„±**: ì „ì²´ ë³´ê³ ì„œì˜ ì–´ì¡°ì™€ í˜•ì‹ í†µì¼
- **ì™„ê²°ì„±**: ê° ì„¹ì…˜ì´ ë…ë¦½ì ìœ¼ë¡œë„ ì´í•´ ê°€ëŠ¥
- **ì •í™•ì„±**: ì›ë³¸ ìë§‰ ë‚´ìš© ì™œê³¡ ì—†ì´ ì¬êµ¬ì„±
- **ê°€ë…ì„±**: ëª…í™•í•œ ì œëª©, ë¶€ì œëª©, ë‹¨ë½ êµ¬ë¶„
- **ì™„ì „ì„±**: ì˜ìƒì˜ ëª¨ë“  ì¤‘ìš”í•œ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬, ë…ìê°€ ì˜ìƒì„ ë³´ì§€ ì•Šì•„ë„ ì „ì²´ ë‚´ìš©ì„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤."""),
    ("human", "{input}")
])

def structure_report(caption: str) -> str:
    """ìë§‰ì„ êµ¬ì¡°í™”ëœ ë³´ê³ ì„œë¡œ ë³€í™˜"""
    try:
        messages = structure_prompt.format_messages(input=caption)
        response = llm.invoke(messages)
        return response.content.strip()
    except Exception as e:
        logger.error(f"ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
        return f"[ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}]"

report_agent_executor_runnable = RunnableLambda(structure_report)

# ========== 6. í—¬í¼ í´ë˜ìŠ¤ë“¤ ==========
class ToolAgent(Runnable):
    """ë‹¨ìˆœ ë„êµ¬ë¥¼ LangGraph ë…¸ë“œë¡œ ë³€í™˜"""
    def __init__(self, tool_func, input_key: str, output_key: str):
        self.tool_func = tool_func
        self.input_key = input_key
        self.output_key = output_key

    def invoke(self, state: Dict[str, Any], config: Optional[Any] = None) -> Dict[str, Any]:
        input_value = state.get(self.input_key, "")
        result = self.tool_func(input_value)
        return {**state, self.output_key: result}

class LangGraphAgentNode(Runnable):
    """LangChain Runnableì„ LangGraph ë…¸ë“œë¡œ ë³€í™˜"""
    def __init__(self, runnable, input_key: str, output_key: str):
        self.runnable = runnable
        self.input_key = input_key
        self.output_key = output_key

    def invoke(self, state: Dict[str, Any], config: Optional[Any] = None) -> Dict[str, Any]:
        input_value = state.get(self.input_key, "")
        result = self.runnable.invoke(input_value)
        return {**state, self.output_key: result}

# ========== 7. ì‹œê°í™” ìš”ì²­ ë¶„ì„ ì—ì´ì „íŠ¸ ==========
CONTEXT_ANALYSIS_PROMPT = """
ë‹¹ì‹ ì€ ë³´ê³ ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì‹œê°í™”ê°€ í•„ìš”í•œ ë¶€ë¶„ì„ ì‹ë³„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì„ë¬´
1. ë³´ê³ ì„œ ë‚´ìš©ì„ ê¹Šì´ ë¶„ì„
2. ì‹œê°í™”ê°€ íš¨ê³¼ì ì¸ ë‚´ìš© ì „ë‹¬ì— ë„ì›€ë  ë¶€ë¶„ ì‹ë³„ 
3. ì‹œê°í™”ì™€ ê´€ë ¨ëœ **ì •í™•í•œ ì›ë³¸ í…ìŠ¤íŠ¸ ë¬¸ë‹¨** ì¶”ì¶œ

## ë³´ê³ ì„œ ë¶„ì„
{report_text}

## ì‘ì—… ë‹¨ê³„
1. **ì „ì²´ ì£¼ì œì™€ íë¦„ íŒŒì•…**
2. **ì‹œê°í™”ê°€ ë„ì›€ë  ë¶€ë¶„ ì‹ë³„** (ë¹„êµ, ê³¼ì •, ê°œë…, ë°ì´í„°, êµ¬ì¡°, íë¦„ ë“±)
3. **ì‹œê°í™”ì™€ ì§ì ‘ ê´€ë ¨ëœ ì™„ì „í•œ ë¬¸ë‹¨ ì¶”ì¶œ**

## ì¤‘ìš” ì§€ì¹¨
- **related_content**ì—ëŠ” ì‹œê°í™”ì™€ ì§ì ‘ ê´€ë ¨ëœ **ì™„ì „í•œ ë¬¸ë‹¨**ì„ í¬í•¨í•˜ì„¸ìš”
- ë¬¸ì¥ì´ ì¤‘ê°„ì— ëŠê¸°ì§€ ì•Šë„ë¡ **ì™„ì„±ëœ ë¬¸ì¥ë“¤**ë¡œ êµ¬ì„±
- ì‹œê°í™” ì£¼ì œì™€ **ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë‚´ìš©**ë§Œ ì„ íƒ
- ìµœì†Œ 100ì ì´ìƒì˜ ì˜ë¯¸ ìˆëŠ” í…ìŠ¤íŠ¸ ë¸”ë¡ ì œê³µ

## ì¶œë ¥ í˜•ì‹
```json
{{
  "visualization_requests": [
    {{
      "purpose": "comparison|process|concept|overview|detail",
      "content_description": "ì‹œê°í™”í•  êµ¬ì²´ì  ë‚´ìš©",
      "related_content": "ì‹œê°í™”ì™€ ì§ì ‘ ê´€ë ¨ëœ ì™„ì „í•œ ì›ë³¸ ë¬¸ë‹¨"
    }}
  ]
}}
```

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

class ContextAnalysisAgent(Runnable):
    def invoke(self, state: Dict[str, Any], config: Optional[Any] = None) -> Dict[str, Any]:
        report_text = state.get("report_text", "")
        
        logger.info("ğŸ·ï¸ ì‹œê°í™” ìš”ì²­ ë¶„ì„ ì‹œì‘...")
        
        try:
            prompt = CONTEXT_ANALYSIS_PROMPT.format(report_text=report_text)
            response = llm.invoke(prompt)
            content = response.content.strip()
            
            start_idx = content.find('{')
            end_idx = content.rfind('}')
            
            if start_idx != -1 and end_idx != -1:
                json_part = content[start_idx:end_idx+1]
                result = json.loads(json_part)
                
                viz_requests = result.get('visualization_requests', [])
                logger.info(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(viz_requests)}ê°œ ì‹œê°í™” ìš”ì²­")
                
                for i, req in enumerate(viz_requests):
                    content_len = len(req.get('related_content', ''))
                    logger.info(f"   ìš”ì²­ {i+1}: {req.get('purpose', 'unknown')} - {content_len}ì")
                
                return {**state, "visualization_requests": viz_requests}
            else:
                logger.error("JSON íŒŒì‹± ì‹¤íŒ¨")
                return {**state, "visualization_requests": []}
                
        except Exception as e:
            logger.error(f"ì‹œê°í™” ìš”ì²­ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {**state, "visualization_requests": []}

# ========== 8. ì‹œê°í™” ìƒì„± ì—ì´ì „íŠ¸ ==========
VISUALIZATION_GENERATION_PROMPT = """
ë‹¹ì‹ ì€ íŠ¹ì • íƒœê·¸ì™€ ë§¥ë½ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ì‹œê°í™”ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.


## ì‹œê°í™” ìš”ì²­ ì •ë³´
- **ëª©ì **: {purpose}
- **ë‚´ìš©**: {content_description}

## ì›ë³¸ í…ìŠ¤íŠ¸(ì´ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”): {related_content}


## ì „ì²´ ìë§‰ (ì¶”ê°€ ì°¸ê³ ìš©)
{caption_context}


## ì§€ì¹¨
1. ì œê³µëœ ë§¥ë½ê³¼ ë°ì´í„°ë¥¼ ì •í™•íˆ í™œìš©
2. ë…ì ì´í•´ë¥¼ ìµœëŒ€í™”
3. ìœ„ ì›ë³¸ í…ìŠ¤íŠ¸ì™€ ì „ì²´ ìë§‰ì—ì„œ ëª…ì‹œëœ ì •ë³´ë§Œ ì‚¬ìš©. **ì›ë³¸ í…ìŠ¤íŠ¸, ì „ì²´ ìë§‰ì— ì—†ëŠ” ì„ì˜ì˜ ë°ì´í„°ë¥¼ ë„£ì§€ ë§ ê²ƒ**
4. ìš”ì²­ëœ ëª©ì ì— ì •í™•íˆ ë¶€í•©í•˜ëŠ” ì‹œê°í™” ìƒì„±


## ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œê°í™” íƒ€ì…
- **chartjs**: ë°ì´í„° ë¹„êµ, íŠ¸ë Œë“œ, ë¹„ìœ¨
- **plotly**: ìˆ˜í•™ì /ê³¼í•™ì  ê·¸ë˜í”„, ë³µì¡í•œ ë°ì´í„°
- **mermaid**: í”„ë¡œì„¸ìŠ¤, í”Œë¡œìš°ì°¨íŠ¸, íƒ€ì„ë¼ì¸
- **markmap**: ê°œë… ê´€ê³„, ë§ˆì¸ë“œë§µ, ë¶„ë¥˜ ì²´ê³„
- **table**: êµ¬ì¡°í™”ëœ ì •ë³´, ë¹„êµí‘œ

ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

**1. Chart.js ì°¨íŠ¸:**
{{
  "type": "chartjs",
  "chart_type": "bar|line|pie|radar|scatter",
  "title": "ì°¨íŠ¸ ì œëª©",
  "config": {{
    "type": "bar",
    "data": {{
      "labels": ["í•­ëª©1", "í•­ëª©2", "í•­ëª©3"],
      "datasets": [{{
        "label": "ë°ì´í„°ì…‹ ì´ë¦„",
        "data": [10, 20, 30],
        "backgroundColor": ["#FF6384", "#36A2EB", "#FFCE56"]
      }}]
    }},
    "options": {{
      "responsive": true,
      "maintainAspectRatio": false
    }}
  }},
  "insight": "ì´ ì°¨íŠ¸ë¥¼ í†µí•´ ì–»ì„ ìˆ˜ ìˆëŠ” ì¸ì‚¬ì´íŠ¸"
}}

**2. Plotly ìˆ˜í•™/ê³¼í•™:**
{{
  "type": "plotly", 
  "chart_type": "function|scatter|heatmap|3d|line charts|pie charts|bubble charts|histograms",
  "title": "ê·¸ë˜í”„ ì œëª©",
  "config": {{
    "data": [{{
      "x": [1, 2, 3, 4],
      "y": [10, 11, 12, 13],
      "type": "scatter",
      "mode": "lines+markers"
    }}],
    "layout": {{
      "title": "ê·¸ë˜í”„ ì œëª©",
      "xaxis": {{"title": "Xì¶•"}},
      "yaxis": {{"title": "Yì¶•"}}
    }}
  }},
  "insight": "ì´ ê·¸ë˜í”„ë¥¼ í†µí•´ ì–»ì„ ìˆ˜ ìˆëŠ” ì¸ì‚¬ì´íŠ¸"
}}

**3. Mermaid ë‹¤ì´ì–´ê·¸ë¨:**
{{
  "type": "mermaid",
  "diagram_type": "flowchart|timeline|concept",  
  "title": "ë‹¤ì´ì–´ê·¸ë¨ ì œëª©",
  "code": "graph TD\\n    A[Start] --> B[Process]\\n    B --> C[End]",
  "insight": "ì´ ë‹¤ì´ì–´ê·¸ë¨ì„ í†µí•´ ì–»ì„ ìˆ˜ ìˆëŠ” ì¸ì‚¬ì´íŠ¸"
}}

**4. Markmap ë§ˆì¸ë“œë§µ:**
{{
  "type": "markmap",
  "title": "ë§ˆì¸ë“œë§µ ì œëª©",
  "markdown": "# ì¤‘ì‹¬ ì£¼ì œ\\n\\n## í° ë¶„ë¥˜ 1\\n\\n- ì„¸ë¶€ì‚¬í•­ 1\\n- ì„¸ë¶€ì‚¬í•­ 2\\n  - í•˜ìœ„ í•­ëª©\\n\\n## í° ë¶„ë¥˜ 2\\n\\n- ì„¸ë¶€ì‚¬í•­ A\\n- ì„¸ë¶€ì‚¬í•­ B",
  "insight": "ì´ ë§ˆì¸ë“œë§µì„ í†µí•´ ì–»ì„ ìˆ˜ ìˆëŠ” ì¸ì‚¬ì´íŠ¸"
}}

**5. HTML í…Œì´ë¸”:**
{{
  "type": "table",
  "title": "í‘œ ì œëª©", 
  "data": {{
    "headers": ["í•­ëª©", "ê°’", "ì„¤ëª…"],
    "rows": [
      ["í•­ëª©1", "ê°’1", "ì„¤ëª…1"],
      ["í•­ëª©2", "ê°’2", "ì„¤ëª…2"]
    ]
  }},
  "insight": "ì´ í‘œë¥¼ í†µí•´ ì–»ì„ ìˆ˜ ìˆëŠ” ì¸ì‚¬ì´íŠ¸"
}}

**6. ì°½ì˜ì  ì œì•ˆ:**
{{
  "type": "creative",
  "method": "ì œì•ˆí•˜ëŠ” ë°©ë²•",
  "description": "ì–´ë–»ê²Œ êµ¬í˜„í• ì§€",
  "insight": "ì™œ ì´ ë°©ë²•ì´ ìµœì ì¸ì§€"
}}

## ğŸ” ì‹¤ì œ ì‘ì—… ê³¼ì •

1. **ì›ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„**: êµ¬ì²´ì  ìˆ˜ì¹˜, í•­ëª©, ê´€ê³„ ì¶”ì¶œ
2. **ë°ì´í„° ìœ í˜• íŒë‹¨**: ìˆ˜ì¹˜í˜•/êµ¬ì¡°í˜•/ê°œë…í˜• êµ¬ë¶„
3. **ì ì ˆí•œ íƒ€ì… ì„ íƒ**: ìœ„ ê°€ì´ë“œì— ë”°ë¼ ì„ íƒ
4. **ì›ë³¸ ê¸°ë°˜ ìƒì„±**: ì¶”ì¶œëœ ì •ë³´ë§Œìœ¼ë¡œ ì‹œê°í™” êµ¬ì„±
5. **data_source ì¶”ê°€**: ì›ë³¸ì—ì„œ ì¸ìš©í•œ êµ¬ì²´ì  ë¶€ë¶„ ëª…ì‹œ


JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

class TargetedVisualizationAgent(Runnable):
    def invoke(self, state: Dict[str, Any], config: Optional[Any] = None) -> Dict[str, Any]:
        visualization_requests = state.get("visualization_requests", [])
        caption_context = state.get("caption", "")
        
        if not visualization_requests:
            logger.info("âŒ ì‹œê°í™” ìš”ì²­ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {**state, "generated_visualizations": []}
        
        logger.info(f"ğŸ¨ {len(visualization_requests)}ê°œ ì‹œê°í™” ìƒì„± ì‹œì‘...")
        
        generated_visualizations = []
        
        for i, req in enumerate(visualization_requests):
            # ğŸ”§ ìˆ˜ì •: tag_id ëŒ€ì‹  ì¸ë±ìŠ¤ ì‚¬ìš©
            viz_id = f"viz_{i+1}"
            logger.info(f"ğŸ¯ ì‹œê°í™” {i+1}/{len(visualization_requests)} ìƒì„± ì¤‘... (ID: {viz_id})")
            
            try:
                prompt = VISUALIZATION_GENERATION_PROMPT.format(
                    purpose=req.get('purpose', ''),
                    content_description=req.get('content_description', ''),
                    related_content=req.get('related_content', ''),
                    caption_context=caption_context[:1000]  # ê¸¸ì´ ì œí•œ
                )
                
                response = llm.invoke(prompt)
                content = response.content.strip()
                
                start_idx = content.find('{')
                end_idx = content.rfind('}')
                
                if start_idx != -1 and end_idx != -1:
                    json_part = content[start_idx:end_idx+1]
                    viz_result = json.loads(json_part)
                    
                    generated_visualizations.append({
                        "viz_id": viz_id,  # ğŸ”§ ìˆ˜ì •: tag_id ëŒ€ì‹  viz_id
                        "original_request": req,
                        "visualization": viz_result
                    })
                    
                    logger.info(f"âœ… ì‹œê°í™” {viz_id} ìƒì„± ì„±ê³µ")
                else:
                    logger.warning(f"âš ï¸ ì‹œê°í™” {viz_id} JSON íŒŒì‹± ì‹¤íŒ¨")
                    
            except Exception as e:
                logger.error(f"âŒ ì‹œê°í™” {viz_id} ìƒì„± ì‹¤íŒ¨: {e}")
        
        logger.info(f"ğŸ¨ ì‹œê°í™” ìƒì„± ì™„ë£Œ: {len(generated_visualizations)}/{len(visualization_requests)}ê°œ ì„±ê³µ")
        
        return {**state, "generated_visualizations": generated_visualizations}

# ========== 9. ìµœì¢… ì¡°ë¦½ ì—ì´ì „íŠ¸ ==========
SMART_FINAL_ASSEMBLY_PROMPT = """
ë‹¹ì‹ ì€ ë³´ê³ ì„œì™€ ì‹œê°í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¡°í•©í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì„ë¬´:
ì›ë³¸ ë³´ê³ ì„œë¥¼ ì ì ˆí•œ ì„¹ì…˜ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ê° ì‹œê°í™”ë¥¼ ê°€ì¥ ì–´ìš¸ë¦¬ëŠ” ìœ„ì¹˜ì— ë°°ì¹˜í•˜ì„¸ìš”.

## ì›ë³¸ ë³´ê³ ì„œ:
{report_text}

## ìƒì„±ëœ ì‹œê°í™” ëª©ë¡:
{visualizations_summary}

## ë°°ì¹˜ ì›ì¹™:
1. **í…ìŠ¤íŠ¸ ìœ ì‚¬ì„±**: ì‹œê°í™”ì˜ related_contentì™€ ê°€ì¥ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ ë¶€ë¶„ ì°¾ê¸°
2. **ë…¼ë¦¬ì  íë¦„**: ë…ìê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆœì„œ
3. **ì„¹ì…˜ ì™„ê²°ì„±**: ê° ì„¹ì…˜ì´ ë…ë¦½ì ìœ¼ë¡œë„ ì´í•´ ê°€ëŠ¥í•˜ë„ë¡

## ì‘ì—… ë°©ë²•:
1. ì›ë³¸ ë³´ê³ ì„œë¥¼ ë…¼ë¦¬ì  ì„¹ì…˜ìœ¼ë¡œ ë¶„í•  (ì œëª©, ì†Œì œëª©, ì£¼ìš” ë¬¸ë‹¨ ê¸°ì¤€)
2. ê° ì‹œê°í™”ì˜ related_contentì™€ ë§¤ì¹­ë˜ëŠ” ì„¹ì…˜ ì‹ë³„
3. í•´ë‹¹ ì„¹ì…˜ ì§í›„ì— ì‹œê°í™” ë°°ì¹˜
4. ì „ì²´ì ì¸ ì½ê¸° íë¦„ ìµœì í™”

## ì¶œë ¥ í˜•ì‹:
```json
{{
  "sections": [
    {{
      "type": "text",
      "content": "ì²« ë²ˆì§¸ ì„¹ì…˜ì˜ ì™„ì „í•œ í…ìŠ¤íŠ¸ ë‚´ìš©",
      "section_info": "ì„¹ì…˜ ì„¤ëª… (ì„ íƒì‚¬í•­)"
    }},
    {{
      "type": "visualization",
      "viz_index": 0,
      "placement_reason": "ì´ ìœ„ì¹˜ì— ë°°ì¹˜í•œ ì´ìœ ",
      "content_match_score": "ë†’ìŒ|ì¤‘ê°„|ë‚®ìŒ"
    }},
    {{
      "type": "text", 
      "content": "ë‘ ë²ˆì§¸ ì„¹ì…˜ì˜ ì™„ì „í•œ í…ìŠ¤íŠ¸ ë‚´ìš©"
    }}
  ],
  "assembly_summary": {{
    "total_text_sections": ìˆ«ì,
    "total_visualizations": ìˆ«ì,
    "matching_method": "ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ë§¤ì¹­í–ˆëŠ”ì§€"
  }}
}}
```

## ì¤‘ìš”ì‚¬í•­:
- **ì›ë³¸ ë³´ê³ ì„œì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ë°˜ë“œì‹œ í¬í•¨**í•˜ì„¸ìš”
- í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ê±°ë‚˜ ìƒëµí•˜ì§€ ë§ˆì„¸ìš”
- ê° ì‹œê°í™”ëŠ” ì •í™•íˆ í•œ ë²ˆë§Œ ë°°ì¹˜í•˜ì„¸ìš”

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

class SmartFinalAssemblyAgent(Runnable):
    """ê¸°ì¡´ ë°©ì‹ + ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ì„ ê²°í•©í•œ ì¡°ë¦½ ì—ì´ì „íŠ¸"""
    
    def invoke(self, state: Dict[str, Any], config: Optional[Any] = None) -> Dict[str, Any]:
        report_text = state.get("report_text", "")
        generated_visualizations = state.get("generated_visualizations", [])
        
        logger.info("ğŸ”§ ìŠ¤ë§ˆíŠ¸ ìµœì¢… ì¡°ë¦½ ì‹œì‘...")
        
        if not generated_visualizations:
            logger.info("âš ï¸ ì‹œê°í™”ê°€ ì—†ì–´ì„œ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜")
            return {
                **state,
                "final_output": {
                    "format": "text_only",
                    "sections": [{"type": "text", "content": report_text}],
                    "total_paragraphs": 1,
                    "total_visuals": 0
                }
            }
        
        # ì‹œê°í™” ìš”ì•½ ì •ë³´ ìƒì„±
        viz_summary = []
        for i, viz in enumerate(generated_visualizations):
            original_req = viz.get("original_request", {})
            viz_config = viz.get("visualization", {})
            
            summary = {
                "index": i,
                "title": viz_config.get("title", f"ì‹œê°í™” {i+1}"),
                "purpose": original_req.get("purpose", ""),
                "description": original_req.get("content_description", ""),
                "related_content_preview": original_req.get("related_content", "")[:150] + "..."
            }
            viz_summary.append(summary)
        
        try:
            prompt = SMART_FINAL_ASSEMBLY_PROMPT.format(
                report_text=report_text,
                visualizations_summary=json.dumps(viz_summary, indent=2, ensure_ascii=False)
            )
            
            response = llm.invoke(prompt)
            content = response.content.strip()
            
            start_idx = content.find('{')
            end_idx = content.rfind('}')
            
            if start_idx != -1 and end_idx != -1:
                json_part = content[start_idx:end_idx+1]
                result = json.loads(json_part)
                
                sections = result.get("sections", [])
                assembly_summary = result.get("assembly_summary", {})
                
                # ì‹œê°í™” ì •ë³´ ë³´ê°•
                enhanced_sections = []
                for section in sections:
                    if section.get("type") == "visualization":
                        viz_index = section.get("viz_index", 0)
                        if 0 <= viz_index < len(generated_visualizations):
                            viz_data = generated_visualizations[viz_index]
                            enhanced_sections.append({
                                **section,
                                "config": viz_data["visualization"],
                                "original_request": viz_data["original_request"]
                            })
                        else:
                            logger.warning(f"âš ï¸ ì˜ëª»ëœ ì‹œê°í™” ì¸ë±ìŠ¤: {viz_index}")
                    else:
                        enhanced_sections.append(section)
                
                # í†µê³„ ê³„ì‚°
                text_count = len([s for s in enhanced_sections if s["type"] == "text"])
                viz_count = len([s for s in enhanced_sections if s["type"] == "visualization"])
                
                final_output = {
                    "format": "smart_assembly",
                    "sections": enhanced_sections,
                    "total_paragraphs": text_count,
                    "total_visuals": viz_count,
                    "assembly_stats": assembly_summary,
                    "assembly_method": "content_similarity_matching"
                }
                
                logger.info(f"ğŸ”§ ìŠ¤ë§ˆíŠ¸ ì¡°ë¦½ ì™„ë£Œ!")
                logger.info(f"ğŸ“Š ê²°ê³¼: í…ìŠ¤íŠ¸ {text_count}ê°œ, ì‹œê°í™” {viz_count}ê°œ")
                
                return {**state, "final_output": final_output}
            else:
                logger.error("JSON íŒŒì‹± ì‹¤íŒ¨, í´ë°± ëª¨ë“œë¡œ ì „í™˜")
                return self._fallback_simple_assembly(state)
                
        except Exception as e:
            logger.error(f"ìŠ¤ë§ˆíŠ¸ ì¡°ë¦½ ì‹¤íŒ¨: {e}, í´ë°± ëª¨ë“œë¡œ ì „í™˜")
            return self._fallback_simple_assembly(state)
    
    def _fallback_simple_assembly(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """í´ë°±: ê¸°ì¡´ ë°©ì‹ê³¼ ìœ ì‚¬í•œ ë‹¨ìˆœ ì¡°ë¦½"""
        report_text = state.get("report_text", "")
        generated_visualizations = state.get("generated_visualizations", [])
        
        logger.info("ğŸ”„ í´ë°±: ë‹¨ìˆœ ì¡°ë¦½ ëª¨ë“œ")
        
        # í…ìŠ¤íŠ¸ë¥¼ ë¬¸ë‹¨ë³„ë¡œ ë¶„í• 
        paragraphs = [p.strip() for p in report_text.split('\n\n') if p.strip()]
        
        sections = []
        
        # ì²« ë²ˆì§¸ ì ˆë°˜ì˜ í…ìŠ¤íŠ¸
        mid_point = len(paragraphs) // 2
        if mid_point > 0:
            first_half = '\n\n'.join(paragraphs[:mid_point])
            sections.append({"type": "text", "content": first_half})
        
        # ì‹œê°í™”ë“¤ ì‚½ì…
        for i, viz in enumerate(generated_visualizations):
            sections.append({
                "type": "visualization",
                "viz_index": i,
                "config": viz["visualization"],
                "original_request": viz["original_request"],
                "placement_reason": "í´ë°± ëª¨ë“œ - ì¤‘ê°„ ìœ„ì¹˜ ë°°ì¹˜"
            })
        
        # ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸
        if mid_point < len(paragraphs):
            second_half = '\n\n'.join(paragraphs[mid_point:])
            sections.append({"type": "text", "content": second_half})
        
        return {
            **state,
            "final_output": {
                "format": "fallback_simple",
                "sections": sections,
                "total_paragraphs": 2 if len(paragraphs) > 1 else 1,
                "total_visuals": len(generated_visualizations),
                "assembly_method": "fallback_paragraph_split"
            }
        }

# ========== ê·¸ë˜í”„ êµ¬ì„± ìˆ˜ì • (ì¡°ë¦½ ì—ì´ì „íŠ¸ë§Œ êµì²´) ==========
def build_hybrid_graph():
    builder = StateGraph(state_schema=ImprovedGraphState)
    
    builder.add_node("caption_node", ToolAgent(extract_youtube_caption_tool, "youtube_url", "caption"))
    builder.add_node("report_node", LangGraphAgentNode(report_agent_executor_runnable, "caption", "report_text"))
    builder.add_node("tagging_node", ContextAnalysisAgent())  # ê¸°ì¡´ ìœ ì§€
    builder.add_node("visualization_node", TargetedVisualizationAgent())  # ê¸°ì¡´ ìœ ì§€  
    builder.add_node("assembly_node", SmartFinalAssemblyAgent())  # ìƒˆë¡œìš´ ìŠ¤ë§ˆíŠ¸ ì¡°ë¦½
    
    builder.set_entry_point("caption_node")
    builder.add_edge("caption_node", "report_node") 
    builder.add_edge("report_node", "tagging_node")
    builder.add_edge("tagging_node", "visualization_node")
    builder.add_edge("visualization_node", "assembly_node")
    builder.add_edge("assembly_node", "__end__")
    
    return builder.compile()

# í•˜ì´ë¸Œë¦¬ë“œ ê·¸ë˜í”„
hybrid_graph = build_hybrid_graph()

# ========== ì‹¤í–‰ í•¨ìˆ˜ ==========
@traceable(name="hybrid-architecture-youtube-report")
def run_hybrid_architecture(youtube_url: str) -> Dict[str, Any]:
    """í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ë¡œ YouTube ë³´ê³ ì„œ ìƒì„±"""
    logger.info("\nğŸš€ [Hybrid Architecture] ì‹¤í–‰ ì‹œì‘")
    logger.info(f"ğŸ¯ ì…ë ¥ URL: {youtube_url}")
    
    try:
        result = hybrid_graph.invoke({"youtube_url": youtube_url})
        logger.info("\nâœ… [Hybrid Architecture] ì‹¤í–‰ ì™„ë£Œ")
        
        final_output = result.get('final_output', {})
        logger.info(f"ğŸ“¦ ìµœì¢… ê²°ê³¼: í…ìŠ¤íŠ¸ {final_output.get('total_paragraphs', 0)}ê°œ, ì‹œê°í™” {final_output.get('total_visuals', 0)}ê°œ")
        logger.info(f"ğŸ”§ ì¡°ë¦½ ë°©ì‹: {final_output.get('assembly_method', 'unknown')}")
        
        return result
    except Exception as e:
        logger.error(f"\nâŒ [Hybrid Architecture] ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return {
            "youtube_url": youtube_url,
            "final_output": {
                "format": "error",
                "error": str(e),
                "sections": [],
                "total_paragraphs": 0,
                "total_visuals": 0
            }
        }
# ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
run_graph = run_hybrid_architecture