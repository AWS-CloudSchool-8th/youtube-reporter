import os
import requests
import json
from typing import TypedDict, List

import boto3
import uuid
import time
from dotenv import load_dotenv
from langgraph.graph import StateGraph
from langchain_core.runnables import Runnable, RunnableLambda
from langchain_aws import ChatBedrock
from langchain_core.prompts import ChatPromptTemplate
from langsmith.run_helpers import traceable
from langchain_experimental.tools import PythonREPLTool

# ========== 1. ìƒíƒœ ì •ì˜ ==========
class GraphState(TypedDict):
    youtube_url: str
    caption: str
    report_text: str
    visual_blocks: List[dict]
    visual_results: List[dict]
    final_output: dict

# ========== 2. í™˜ê²½ ë³€ìˆ˜ ë¡œë”© ==========
load_dotenv()
VIDCAP_API_KEY = os.getenv("VIDCAP_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ========== 3. Tool ì •ì˜ ==========
def extract_youtube_caption_tool(youtube_url: str) -> str:
    api_url = "https://vidcap.xyz/api/v1/youtube/caption"
    params = {"url": youtube_url, "locale": "ko"}
    headers = {"Authorization": f"Bearer {VIDCAP_API_KEY}"}
    response = requests.get(api_url, params=params, headers=headers)
    response.raise_for_status()
    return response.json().get("data", {}).get("content", "")

def generate_visuals(description: str, vtype: str = "diagram") -> str:
    dalle_api = "https://api.openai.com/v1/images/generations"
    dalle_prompt = make_image_prompt(description, vtype)

    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "dall-e-3",
        "prompt": dalle_prompt,
        "n": 1,
        "size": "1024x1024"
    }
    response = requests.post(dalle_api, headers=headers, json=payload)
    response.raise_for_status()
    return response.json().get("data", [{}])[0].get("url", "[Image generation failed]")

def upload_to_s3(file_path: str, object_name: str = None) -> str:
    s3 = boto3.client("s3", region_name=os.getenv("AWS_REGION"))
    bucket_name = os.getenv("S3_BUCKET_NAME")
    object_name = object_name or os.path.basename(file_path)

    s3.upload_file(file_path, bucket_name, object_name, ExtraArgs={"ACL": "public-read"})

    return f"https://{bucket_name}.s3.{os.getenv('AWS_REGION')}.amazonaws.com/{object_name}"

'''
def merge_report_and_visuals(report_text: str, visuals: List[dict]) -> dict:
    sections = [{"type": "paragraph", "content": report_text}]
    for v in visuals:
        if not v.get("url") or not v.get("type"):
            continue
        sections.append({"type": v["type"], "src": v["url"]})
    return {"format": "json", "sections": sections}
'''
def merge_report_and_visuals(report_text: str, visuals: List[dict]) -> dict:
    paragraphs = [p.strip() for p in report_text.strip().split("\n") if p.strip()]
    n, v = len(paragraphs), len(visuals)
    sections = []

    # ë¬¸ë‹¨ê³¼ ì‹œê°í™”ë¥¼ êµì°¨ ì‚½ì…
    for i, para in enumerate(paragraphs):
        sections.append({"type": "paragraph", "content": para})
        if i < v:
            vis = visuals[i]
            if vis.get("url") and vis.get("type"):
                sections.append({"type": vis["type"], "src": vis["url"]})

    # ë‚¨ì€ ì‹œê°í™” ë¸”ë¡ì´ ìˆë‹¤ë©´ ì¶”ê°€
    for j in range(len(paragraphs), v):
        vis = visuals[j]
        if vis.get("url") and vis.get("type"):
            sections.append({"type": vis["type"], "src": vis["url"]})

    return {"format": "json", "sections": sections}


# ========== 4. ë³´ê³ ì„œ ì—ì´ì „íŠ¸ ==========
structure_prompt = ChatPromptTemplate.from_messages([
    ("system", "ë„ˆëŠ” ìœ íŠœë¸Œ ìë§‰ì„ ë°”íƒ•ìœ¼ë¡œ ë…¼ë¦¬ì ì´ê³  í’ë¶€í•œ ì„¤ëª…ì´ ë‹´ê¸´ ì „ë¬¸ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ê³ ê¸‰ AIì•¼. ë‹¤ìŒ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:\n\n"
     "1. ì „ì²´ ìë§‰ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì£¼ì œë³„ë¡œ í•µì‹¬ íë¦„ì„ ì¬êµ¬ì„±í•˜ê³ , ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ì¬ë°°ì—´í•´.\n"
     "2. ë‹¨ìˆœí•œ ìë§‰ ë‚˜ì—´ì„ í”¼í•˜ê³ , ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ í•˜ë‚˜ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ê¸€ë¡œ ì´ì–´ì¤˜.\n"
     "3. ê° ë¬¸ë‹¨ì€ ë‹¤ìŒì˜ êµ¬ì¡°ë¥¼ ë”°ë¥´ë„ë¡ í•´:\n"
     "   - ğŸ”¹ ì£¼ì œ ìš”ì•½ (ë¬¸ë‹¨ì˜ ì¤‘ì‹¬ ë©”ì‹œì§€)\n"
     "   - ğŸ”¹ ê°œë… ì„¤ëª… (í•µì‹¬ ê°œë…ì´ë‚˜ ì´ë¡ ì„ ì •í™•í•˜ê³  ì‰½ê²Œ ì„¤ëª…)\n"
     "   - ğŸ”¹ ì˜ˆì‹œ ë° ë¹„ìœ  (ì‹¤ì œ ì‚¬ë¡€ë‚˜ ë…ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ë¹„ìœ  ì‚¬ìš©)\n"
     "4. ì „ì²´ ë¬¸ë‹¨ì€ ìµœì†Œ 4ê°œ ì´ìƒ, ì „ì²´ ê¸¸ì´ëŠ” 500ì ì´ìƒ, ì¤‘ë³µ ì—†ëŠ” ë‚´ìš©ìœ¼ë¡œ êµ¬ì„±í•´.\n"
     "5. ì„¤ëª…ì€ **ì „ë¬¸ê°€ê°€ ì´ˆì‹¬ìì—ê²Œ ê°€ë¥´ì¹˜ë“¯ ìì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ ì¨ì¤˜. ë„ˆë¬´ ê°„ë‹¨í•˜ê±°ë‚˜ ë”±ë”±í•œ ì–´íˆ¬ëŠ” í”¼í•˜ê³ , ë¶€ë“œëŸ¬ìš´ ì„¤ëª…ì²´ë¡œ ì‘ì„±í•´.\n"
     "6. ê° ë¬¸ë‹¨ì€ ì œëª© ì—†ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë˜, ë³´ê³ ì„œì²˜ëŸ¼ ë…¼ë¦¬ì  êµ¬ì¡°ë¥¼ ìœ ì§€í•´.\n"
     "7. í•„ìš”í•˜ë‹¤ë©´ ë¬¸ë§¥ì„ ë³´ì™„í•´ì„œ ì›ë˜ ìë§‰ì— ì—†ë˜ ë¶€ë¶„ë„ ìœ ì¶”í•´ì„œ ì¶”ê°€í•´ë„ ì¢‹ì•„.\n\n"
     "ë§ˆì§€ë§‰ìœ¼ë¡œ, í•˜ë‚˜ì˜ ì™„ê²°ëœ ë³´ê³ ì„œì²˜ëŸ¼ êµ¬ì„±í•´ì¤˜. ì¤‘ê°„ì¤‘ê°„ ëŠê¸°ëŠ” ëŠë‚Œ ì—†ì´ ë¶€ë“œëŸ½ê²Œ ì—°ê²°ë¼ì•¼ í•´."),
    ("human", "{input}")
])

llm = ChatBedrock(
    client=boto3.client("bedrock-runtime", region_name="us-west-2"),
    model_id="anthropic.claude-3-5-sonnet-20241022-v2:0",
    model_kwargs={"temperature": 0.7, "max_tokens": 4096}
)

visual_prompt_template = ChatPromptTemplate.from_messages([
    ("system",
     "ë‹¹ì‹ ì€ ì´ë¯¸ì§€ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì„¤ëª…ì„ ë³´ê³ , "
     "{type} í˜•íƒœì˜ ì‹œê°í™”ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ DALLÂ·E í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. "
     "í•­ìƒ ìµœì†Œí•œì˜ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ(ì˜ˆ: ê²€ì€ ì‹¤ì„ , í° ë°°ê²½, í•µì‹¬ ë ˆì´ë¸”)ë¥¼ í¬í•¨í•˜ê³ , "
     "ë‚´ìš©ì„ ëª…í™•íˆ ì „ë‹¬í•  ìˆ˜ ìˆë„ë¡ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤."),
    ("human", "{description}")
])

def make_image_prompt(description: str, vtype: str) -> str:
    msgs = visual_prompt_template.format_messages(description=description, type=vtype)
    return llm.invoke(msgs).content.strip()

def structure_report(caption: str) -> str:
    messages = structure_prompt.format_messages(input=caption)
    response = llm.invoke(messages)
    return response.content.strip()

report_agent_executor_runnable = RunnableLambda(structure_report)

# ========== 5. ì‹œê°í™” ë¸”ë¡ ë¶„í•´ ==========
visual_split_prompt = ChatPromptTemplate.from_messages([
    ("system", "ë„ˆëŠ” ë³´ê³ ì„œë¥¼ ë‹¤ìŒ í˜•ì‹ì˜ JSON ë°°ì—´ë¡œ ì‹œê°í™” ë¸”ë¡ì„ ì¶œë ¥í•´ì•¼ í•´:\n"
     "[{{\"type\": \"chart\", \"text\": \"...\"}}]\n"
     "typeì€ ë°˜ë“œì‹œ chart, table, image ì¤‘ í•˜ë‚˜ê³ ,\n" # diagram, mindmap ì¶”ê°€ ì˜ˆì •
     "textëŠ” ì„¤ëª… ë¬¸ì¥ì´ë‹¤. key ì´ë¦„ì€ ê¼­ type, textë¥¼ ê·¸ëŒ€ë¡œ ì¨."),
    ("human", "{input}")
])

def _split_report(report_text: str) -> List[dict]:
    response = llm.invoke(visual_split_prompt.format_messages(input=report_text))
    try:
        raw = json.loads(response.content)
        print("ğŸ§ª raw LLM ì‘ë‹µ:", raw)
        if not isinstance(raw, list):
            print("âŒ LLM ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ ì•„ë‹˜")
            return []
        parsed = []
        for i, item in enumerate(raw):
            if isinstance(item, dict):
                parsed.append(item)
            elif isinstance(item, str):
                try:
                    parsed_item = json.loads(item)
                    parsed.append(parsed_item)
                    print(f"âœ… item {i} íŒŒì‹± ì„±ê³µ: {parsed_item}")
                except Exception as e:
                    print(f"âŒ item {i} íŒŒì‹± ì‹¤íŒ¨: {item}, ì˜¤ë¥˜: {e}")
        return parsed
    except Exception as e:
        print("âŒ ì „ì²´ íŒŒì‹± ì‹¤íŒ¨:", e)
        return []

class WrapVisualSplitToState(Runnable):
    def invoke(self, state: dict, config=None):
        start = time.time()
        report_text = state.get("report_text", "")
        visual_blocks = _split_report(report_text)
        print(f"[split_node] ì‹¤í–‰ ì‹œê°„: {round(time.time() - start, 2)}ì´ˆ")
        return {**state, "visual_blocks": visual_blocks}

visual_split_agent_wrapped = WrapVisualSplitToState()

# ========== 6. ì‹œê°í™” ìƒì„± ==========
python_tool = PythonREPLTool()

code_gen_prompt = ChatPromptTemplate.from_messages([
    ("system", "ë‹¤ìŒ ë¬¸ì¥ì„ ì‹œê°í™”í•˜ëŠ” **Python ì½”ë“œë§Œ** ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”. ë°˜ë“œì‹œ matplotlib.pyplot ë˜ëŠ” pandasë¥¼ ì‚¬ìš©í•˜ê³ , ë§ˆì§€ë§‰ ì¤„ì€ plt.savefig('output.png') ë˜ëŠ” df.to_csv('output.csv')ì—¬ì•¼ í•©ë‹ˆë‹¤."),
    ("human", "{input}")
])

def dispatch_visual_block_with_python_tool(blocks: List[dict]) -> List[dict]:
    results = []
    for i, blk in enumerate(blocks):
        print(f"\nğŸ” ë¸”ë¡ {i} ë‚´ìš© í™•ì¸: {blk} (íƒ€ì…: {type(blk)})")
        if isinstance(blk, str):
            blk = blk.strip()
            if not blk:
                print(f"âš ï¸ ë¹ˆ ë¬¸ìì—´ ë¸”ë¡ ë¬´ì‹œë¨.")
                continue
            try:
                blk = json.loads(blk)
                print(f"âœ… ë¬¸ìì—´ íŒŒì‹± ì„±ê³µ: {blk}")
            except Exception as e:
                print(f"âŒ ë¬¸ìì—´ íŒŒì‹± ì‹¤íŒ¨: {e} | ì›ë³¸: {blk}")
                continue
        if not isinstance(blk, dict):
            print(f"âŒ dict íƒ€ì… ì•„ë‹˜. blk = {blk}")
            continue
        t, txt = blk.get("type"), blk.get("text")
        print(f"ğŸ§© type: {t}, text: {txt}")
        if not t or not txt:
            continue
        try:
            if t in ["chart", "table"]:
                code = llm.invoke(code_gen_prompt.format_messages(input=txt)).content
                print("ğŸ§ª ìƒì„±ëœ ì½”ë“œ:\n", code)
                result = python_tool.run(code)
                print("ğŸ› ï¸ ì‹¤í–‰ ê²°ê³¼:", result)

                if os.path.exists("output.png"):
                    # âœ… ê³ ìœ  íŒŒì¼ëª… ìƒì„±
                    unique_filename = f"output-{uuid.uuid4().hex[:8]}.png"
                    os.rename("output.png", unique_filename)

                    # âœ… S3ì— ì—…ë¡œë“œ
                    s3_url = upload_to_s3(unique_filename, object_name=unique_filename)
                    
                    # âœ… ë¡œì»¬ íŒŒì¼ ì‚­ì œ
                    os.remove(unique_filename)

                    url = s3_url
                else:
                    url = f"[Image not created: {result}]"

            elif t == "image":
                url = generate_visuals(txt, vtype=t)

            else:
                url = f"[Unsupported type: {t}]"

            results.append({"type": t, "text": txt, "url": url})

        except Exception as e:
            results.append({"type": t, "text": txt, "url": f"[Error: {e}]"})
    return results

visual_agent_executor_group = RunnableLambda(dispatch_visual_block_with_python_tool)

# ========== 7. Node ì •ì˜ ==========
class ToolAgent(Runnable):
    def __init__(self, func, field: str, output_field: str | None = None):
        self.func = func
        self.field = field
        self.output_field = output_field or field

    def invoke(self, state: dict, config=None):
        start = time.time()
        # print(f"\nğŸ”§ [ToolAgent] ì‹¤í–‰ - field: {self.field}")
        input_value = state.get(self.field)
        # print(f"ğŸ“¥ ì…ë ¥ê°’: {input_value}")
        result = self.func(input_value)
        # print(f"ğŸ“¤ ì¶œë ¥ê°’: {result}")
        print(f"[{self.field}] ì‹¤í–‰ ì‹œê°„: {round(time.time() - start, 2)}ì´ˆ")
        return {**state, self.output_field: result}


class LangGraphAgentNode(Runnable):
    def __init__(self, executor, input_key: str, output_key: str):
        self.executor = executor
        self.input_key = input_key
        self.output_key = output_key

    def invoke(self, state: dict, config=None):
        start = time.time()
        # print(f"\nğŸ§  [LangGraphAgentNode] ì‹¤í–‰ - input_key: {self.input_key}")
        input_val = state[self.input_key]
        # print(f"ğŸ“¥ ì…ë ¥ê°’: {input_val}")
        result = self.executor.invoke(input_val)

        if isinstance(result, dict) and "output" in result:
            obs = result["output"]
        else:
            obs = result

        # print(f"ğŸ“¤ ì¶œë ¥ê°’: {obs}")
        print(f"[{self.input_key} â†’ {self.output_key}] ì‹¤í–‰ ì‹œê°„: {round(time.time() - start, 2)}ì´ˆ")
        return {**state, self.output_key: obs}


class MergeTool(Runnable):
    def invoke(self, state: dict, config=None):
        start = time.time()
        # print("\nğŸ§© [MergeTool] ì‹¤í–‰")
        # print(f"ğŸ“¥ ë³´ê³ ì„œ: {state.get('report_text')}")
        # print(f"ğŸ“¥ ì‹œê°í™”: {state.get('visual_results')}")
        final_output = merge_report_and_visuals(
            state.get("report_text", ""), state.get("visual_results", [])
        )
        # print(f"ğŸ“¤ ìµœì¢… ê²°ê³¼: {final_output}")
        print(f"[MergeTool] ì‹¤í–‰ ì‹œê°„: {round(time.time() - start, 2)}ì´ˆ")
        return {**state, "final_output": final_output}


# ========== 8. FSM êµ¬ì„± ==========
builder = StateGraph(state_schema=GraphState)

builder.add_node("caption_node", ToolAgent(extract_youtube_caption_tool, "youtube_url", "caption"))
builder.add_node("report_node", LangGraphAgentNode(report_agent_executor_runnable, "caption", "report_text"))
builder.add_node("split_node", visual_split_agent_wrapped)
builder.add_node("visual_node", LangGraphAgentNode(visual_agent_executor_group, "visual_blocks", "visual_results"))
builder.add_node("merge_node", MergeTool())

builder.set_entry_point("caption_node")
for src, dst in [
    ("caption_node", "report_node"),
    ("report_node", "split_node"),
    ("split_node", "visual_node"),
    ("visual_node", "merge_node"),
    ("merge_node", "__end__")
]:
    builder.add_edge(src, dst)

compiled_graph = builder.compile()

# ========== 9. ì‹¤í–‰ í•¨ìˆ˜ ==========
@traceable(name="youtube-report-fsm")
def run_graph(youtube_url: str):
    print("\nğŸš€ [run_graph] ì‹¤í–‰ ì‹œì‘")
    print(f"ğŸ¯ ì…ë ¥ URL: {youtube_url}")
    result = compiled_graph.invoke({"youtube_url": youtube_url})
    print("\nâœ… [run_graph] ì‹¤í–‰ ì™„ë£Œ")
    print(f"ğŸ“¦ ìµœì¢… ìƒíƒœ: {json.dumps(result, ensure_ascii=False, indent=2)}")
    return result