import os
import requests
import json
from typing import TypedDict, List

import boto3
import uuid
import time
from dotenv import load_dotenv
from langgraph.graph import StateGraph
from langchain_core.runnables import Runnable, RunnableLambda
from langchain_aws import ChatBedrock
from langchain_core.prompts import ChatPromptTemplate
from langsmith.run_helpers import traceable
from langchain_experimental.tools import PythonREPLTool

# ========== 1. ìƒíƒœ ì •ì˜ ==========
class GraphState(TypedDict):
    youtube_url: str
    caption: str
    report_text: str
    visual_blocks: List[dict]
    visual_results: List[dict]
    final_output: dict

# ========== 2. í™˜ê²½ ë³€ìˆ˜ ë¡œë”© ==========
load_dotenv()
VIDCAP_API_KEY = os.getenv("VIDCAP_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ========== 3. Tool ì •ì˜ ==========
def extract_youtube_caption_tool(youtube_url: str) -> str:
    api_url = "https://vidcap.xyz/api/v1/youtube/caption"
    params = {"url": youtube_url, "locale": "ko"}
    headers = {"Authorization": f"Bearer {VIDCAP_API_KEY}"}
    response = requests.get(api_url, params=params, headers=headers)
    response.raise_for_status()
    return response.json().get("data", {}).get("content", "")

def generate_visuals(prompt: str) -> str:
    dalle_api = "https://api.openai.com/v1/images/generations"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "dall-e-3",
        "prompt": f"Create a simple and clear visual based on this sentence:\n\n{prompt}",
        "n": 1,
        "size": "1024x1024"
    }
    response = requests.post(dalle_api, headers=headers, json=payload)
    response.raise_for_status()
    return response.json().get("data", [{}])[0].get("url", "[Image generation failed]")

def upload_to_s3(file_path: str, object_name: str = None) -> str:
    s3 = boto3.client("s3", region_name=os.getenv("AWS_REGION"))
    bucket_name = os.getenv("S3_BUCKET_NAME")
    object_name = object_name or os.path.basename(file_path)

    s3.upload_file(file_path, bucket_name, object_name, ExtraArgs={"ACL": "public-read"})

    return f"https://{bucket_name}.s3.{os.getenv('AWS_REGION')}.amazonaws.com/{object_name}"

'''
def merge_report_and_visuals(report_text: str, visuals: List[dict]) -> dict:
    sections = [{"type": "paragraph", "content": report_text}]
    for v in visuals:
        if not v.get("url") or not v.get("type"):
            continue
        sections.append({"type": v["type"], "src": v["url"]})
    return {"format": "json", "sections": sections}
'''
def merge_report_and_visuals(report_text: str, visuals: List[dict]) -> dict:
    paragraphs = [p.strip() for p in report_text.strip().split("\n") if p.strip()]
    n, v = len(paragraphs), len(visuals)
    sections = []

    # ë¬¸ë‹¨ê³¼ ì‹œê°í™”ë¥¼ êµì°¨ ì‚½ì…
    for i, para in enumerate(paragraphs):
        sections.append({"type": "paragraph", "content": para})
        if i < v:
            vis = visuals[i]
            if vis.get("url") and vis.get("type"):
                sections.append({"type": vis["type"], "src": vis["url"]})

    # ë‚¨ì€ ì‹œê°í™” ë¸”ë¡ì´ ìˆë‹¤ë©´ ì¶”ê°€
    for j in range(len(paragraphs), v):
        vis = visuals[j]
        if vis.get("url") and vis.get("type"):
            sections.append({"type": vis["type"], "src": vis["url"]})

    return {"format": "json", "sections": sections}


# ========== 4. ë³´ê³ ì„œ ì—ì´ì „íŠ¸ ==========
structure_prompt = ChatPromptTemplate.from_messages([
    ("system", "ë„ˆëŠ” ìœ íŠœë¸Œ ìë§‰ì„ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ì¬ì‘ì„±í•˜ëŠ” AIì•¼. ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¥´ì„¸ìš”:\n"
               "1. ìë§‰ ë‚´ìš©ì„ ì„œìˆ í˜• ë¬¸ì¥ìœ¼ë¡œ ë°”ê¾¸ì„¸ìš”.\n"
               "2. 3ê°œ ì´ìƒì˜ ë¬¸ë‹¨, 300ì ì´ìƒ.\n"
               "3. ê° ë¬¸ë‹¨ì€ ìš”ì•½+ì„¤ëª… í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."),
    ("human", "{input}")
])

llm = ChatBedrock(
    client=boto3.client("bedrock-runtime", region_name="ap-northeast-2"),
    model_id="anthropic.claude-3-haiku-20240307-v1:0",
    model_kwargs={"temperature": 0.0, "max_tokens": 4096}
)

def structure_report(caption: str) -> str:
    messages = structure_prompt.format_messages(input=caption)
    response = llm.invoke(messages)
    return response.content.strip()

report_agent_executor_runnable = RunnableLambda(structure_report)

# ========== 5. ì‹œê°í™” ë¸”ë¡ ë¶„í•´ ==========
visual_split_prompt = ChatPromptTemplate.from_messages([
    ("system", "ë„ˆëŠ” ë³´ê³ ì„œë¥¼ ë‹¤ìŒ í˜•ì‹ì˜ JSON ë°°ì—´ë¡œ ì‹œê°í™” ë¸”ë¡ì„ ì¶œë ¥í•´ì•¼ í•´:\n"
     "[{{\"type\": \"chart\", \"text\": \"...\"}}]\n"
     "typeì€ ë°˜ë“œì‹œ chart, table, image ì¤‘ í•˜ë‚˜ê³ ,\n" # diagram, mindmap ì¶”ê°€ ì˜ˆì •ì •
     "textëŠ” ì„¤ëª… ë¬¸ì¥ì´ë‹¤. key ì´ë¦„ì€ ê¼­ type, textë¥¼ ê·¸ëŒ€ë¡œ ì¨."),
    ("human", "{input}")
])

def _split_report(report_text: str) -> List[dict]:
    response = llm.invoke(visual_split_prompt.format_messages(input=report_text))
    try:
        raw = json.loads(response.content)
        print("ğŸ§ª raw LLM ì‘ë‹µ:", raw)
        if not isinstance(raw, list):
            print("âŒ LLM ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ ì•„ë‹˜")
            return []
        parsed = []
        for i, item in enumerate(raw):
            if isinstance(item, dict):
                parsed.append(item)
            elif isinstance(item, str):
                try:
                    parsed_item = json.loads(item)
                    parsed.append(parsed_item)
                    print(f"âœ… item {i} íŒŒì‹± ì„±ê³µ: {parsed_item}")
                except Exception as e:
                    print(f"âŒ item {i} íŒŒì‹± ì‹¤íŒ¨: {item}, ì˜¤ë¥˜: {e}")
        return parsed
    except Exception as e:
        print("âŒ ì „ì²´ íŒŒì‹± ì‹¤íŒ¨:", e)
        return []

class WrapVisualSplitToState(Runnable):
    def invoke(self, state: dict, config=None):
        start = time.time()
        report_text = state.get("report_text", "")
        visual_blocks = _split_report(report_text)
        print(f"[split_node] ì‹¤í–‰ ì‹œê°„: {round(time.time() - start, 2)}ì´ˆ")
        return {**state, "visual_blocks": visual_blocks}

visual_split_agent_wrapped = WrapVisualSplitToState()

# ========== 6. ì‹œê°í™” ìƒì„± ==========
python_tool = PythonREPLTool()

code_gen_prompt = ChatPromptTemplate.from_messages([
    ("system", "ë‹¤ìŒ ë¬¸ì¥ì„ ì‹œê°í™”í•˜ëŠ” **Python ì½”ë“œë§Œ** ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”. ë°˜ë“œì‹œ matplotlib.pyplot ë˜ëŠ” pandasë¥¼ ì‚¬ìš©í•˜ê³ , ë§ˆì§€ë§‰ ì¤„ì€ plt.savefig('output.png') ë˜ëŠ” df.to_csv('output.csv')ì—¬ì•¼ í•©ë‹ˆë‹¤."),
    ("human", "{input}")
])

def dispatch_visual_block_with_python_tool(blocks: List[dict]) -> List[dict]:
    results = []
    for i, blk in enumerate(blocks):
        print(f"\nğŸ” ë¸”ë¡ {i} ë‚´ìš© í™•ì¸: {blk} (íƒ€ì…: {type(blk)})")
        if isinstance(blk, str):
            blk = blk.strip()
            if not blk:
                print(f"âš ï¸ ë¹ˆ ë¬¸ìì—´ ë¸”ë¡ ë¬´ì‹œë¨.")
                continue
            try:
                blk = json.loads(blk)
                print(f"âœ… ë¬¸ìì—´ íŒŒì‹± ì„±ê³µ: {blk}")
            except Exception as e:
                print(f"âŒ ë¬¸ìì—´ íŒŒì‹± ì‹¤íŒ¨: {e} | ì›ë³¸: {blk}")
                continue
        if not isinstance(blk, dict):
            print(f"âŒ dict íƒ€ì… ì•„ë‹˜. blk = {blk}")
            continue
        t, txt = blk.get("type"), blk.get("text")
        print(f"ğŸ§© type: {t}, text: {txt}")
        if not t or not txt:
            continue
        try:
            if t in ["chart", "table"]:
                code = llm.invoke(code_gen_prompt.format_messages(input=txt)).content
                print("ğŸ§ª ìƒì„±ëœ ì½”ë“œ:\n", code)
                result = python_tool.run(code)
                print("ğŸ› ï¸ ì‹¤í–‰ ê²°ê³¼:", result)

                if os.path.exists("output.png"):
                    # âœ… ê³ ìœ  íŒŒì¼ëª… ìƒì„±
                    unique_filename = f"output-{uuid.uuid4().hex[:8]}.png"
                    os.rename("output.png", unique_filename)

                    # âœ… S3ì— ì—…ë¡œë“œ
                    s3_url = upload_to_s3(unique_filename, object_name=unique_filename)
                    
                    # âœ… ë¡œì»¬ íŒŒì¼ ì‚­ì œ
                    os.remove(unique_filename)

                    url = s3_url
                else:
                    url = f"[Image not created: {result}]"

            elif t == "image":
                url = generate_visuals(txt)

            else:
                url = f"[Unsupported type: {t}]"

            results.append({"type": t, "text": txt, "url": url})

        except Exception as e:
            results.append({"type": t, "text": txt, "url": f"[Error: {e}]"})
    return results

visual_agent_executor_group = RunnableLambda(dispatch_visual_block_with_python_tool)

# ========== 7. Node ì •ì˜ ==========
class ToolAgent(Runnable):
    def __init__(self, func, field: str, output_field: str | None = None):
        self.func = func
        self.field = field
        self.output_field = output_field or field

    def invoke(self, state: dict, config=None):
        start = time.time()
        # print(f"\nğŸ”§ [ToolAgent] ì‹¤í–‰ - field: {self.field}")
        input_value = state.get(self.field)
        # print(f"ğŸ“¥ ì…ë ¥ê°’: {input_value}")
        result = self.func(input_value)
        # print(f"ğŸ“¤ ì¶œë ¥ê°’: {result}")
        print(f"[{self.field}] ì‹¤í–‰ ì‹œê°„: {round(time.time() - start, 2)}ì´ˆ")
        return {**state, self.output_field: result}


class LangGraphAgentNode(Runnable):
    def __init__(self, executor, input_key: str, output_key: str):
        self.executor = executor
        self.input_key = input_key
        self.output_key = output_key

    def invoke(self, state: dict, config=None):
        start = time.time()
        # print(f"\nğŸ§  [LangGraphAgentNode] ì‹¤í–‰ - input_key: {self.input_key}")
        input_val = state[self.input_key]
        # print(f"ğŸ“¥ ì…ë ¥ê°’: {input_val}")
        result = self.executor.invoke(input_val)

        if isinstance(result, dict) and "output" in result:
            obs = result["output"]
        else:
            obs = result

        # print(f"ğŸ“¤ ì¶œë ¥ê°’: {obs}")
        print(f"[{self.input_key} â†’ {self.output_key}] ì‹¤í–‰ ì‹œê°„: {round(time.time() - start, 2)}ì´ˆ")
        return {**state, self.output_key: obs}


class MergeTool(Runnable):
    def invoke(self, state: dict, config=None):
        start = time.time()
        # print("\nğŸ§© [MergeTool] ì‹¤í–‰")
        # print(f"ğŸ“¥ ë³´ê³ ì„œ: {state.get('report_text')}")
        # print(f"ğŸ“¥ ì‹œê°í™”: {state.get('visual_results')}")
        final_output = merge_report_and_visuals(
            state.get("report_text", ""), state.get("visual_results", [])
        )
        # print(f"ğŸ“¤ ìµœì¢… ê²°ê³¼: {final_output}")
        print(f"[MergeTool] ì‹¤í–‰ ì‹œê°„: {round(time.time() - start, 2)}ì´ˆ")
        return {**state, "final_output": final_output}


# ========== 8. FSM êµ¬ì„± ==========
builder = StateGraph(state_schema=GraphState)

builder.add_node("caption_node", ToolAgent(extract_youtube_caption_tool, "youtube_url", "caption"))
builder.add_node("report_node", LangGraphAgentNode(report_agent_executor_runnable, "caption", "report_text"))
builder.add_node("split_node", visual_split_agent_wrapped)
builder.add_node("visual_node", LangGraphAgentNode(visual_agent_executor_group, "visual_blocks", "visual_results"))
builder.add_node("merge_node", MergeTool())

builder.set_entry_point("caption_node")
for src, dst in [
    ("caption_node", "report_node"),
    ("report_node", "split_node"),
    ("split_node", "visual_node"),
    ("visual_node", "merge_node"),
    ("merge_node", "__end__")
]:
    builder.add_edge(src, dst)

compiled_graph = builder.compile()

# ========== 9. ì‹¤í–‰ í•¨ìˆ˜ ==========
@traceable(name="youtube-report-fsm")
def run_graph(youtube_url: str):
    print("\nğŸš€ [run_graph] ì‹¤í–‰ ì‹œì‘")
    print(f"ğŸ¯ ì…ë ¥ URL: {youtube_url}")
    result = compiled_graph.invoke({"youtube_url": youtube_url})
    print("\nâœ… [run_graph] ì‹¤í–‰ ì™„ë£Œ")
    print(f"ğŸ“¦ ìµœì¢… ìƒíƒœ: {json.dumps(result, ensure_ascii=False, indent=2)}")
    return result