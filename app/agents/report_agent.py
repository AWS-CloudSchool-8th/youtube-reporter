# app/agents/report_agent.py
import json
import boto3
from typing import Dict, List, Any
from datetime import datetime
from langchain_aws import ChatBedrock
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import Runnable
from ..core.config import settings  # settings import ì¶”ê°€
from ..models.response import ReportSection, ReportStatistics, ProcessInfo, VisualizationData
from ..utils.logger import get_logger

logger = get_logger(__name__)


class ReportAgent(Runnable):
    """ìš”ì•½ê³¼ ì‹œê°í™”ë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì—ì´ì „íŠ¸"""

    def __init__(self):
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ LLM ì„¤ì • ê°€ì ¸ì˜¤ê¸° (ë¦¬í¬íŠ¸ëŠ” ì¼ê´€ì„±ì´ ì¤‘ìš”í•˜ë¯€ë¡œ ì˜¨ë„ ë‚®ì¶¤)
        llm_config = settings.get_llm_config().copy()
        llm_config["temperature"] = max(llm_config["temperature"] - 0.1, 0.0)  # ë¦¬í¬íŠ¸ëŠ” ë” ì¼ê´€ì„± ìˆê²Œ

        self.llm = ChatBedrock(
            client=boto3.client("bedrock-runtime", region_name=settings.aws_region),
            model_id=settings.bedrock_model_id,
            model_kwargs=llm_config  # í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©!
        )

        logger.info(f"ğŸ“‹ ReportAgent ì´ˆê¸°í™” - ì˜¨ë„: {llm_config['temperature']}, ìµœëŒ€í† í°: {llm_config['max_tokens']}")

    def invoke(self, state: Dict[str, Any], config=None) -> Dict[str, Any]:
        """ìš”ì•½ê³¼ ì‹œê°í™”ë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±"""
        summary = state.get("summary", "")
        visual_sections = state.get("visual_sections", [])
        youtube_url = state.get("youtube_url", "")
        caption = state.get("caption", "")

        if not summary or "[ì˜¤ë¥˜]" in summary:
            logger.warning("ìœ íš¨í•œ ìš”ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {**state, "report_result": self._create_error_report("ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")}

        try:
            logger.info("ğŸ“‹ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")

            # 1. ìš”ì•½ì„ ì„¹ì…˜ìœ¼ë¡œ êµ¬ì¡°í™”
            logger.info("ğŸ“ ìš”ì•½ì„ ì„¹ì…˜ìœ¼ë¡œ êµ¬ì¡°í™” ì¤‘...")
            structured_sections = self._structure_summary(summary)

            # 2. ì‹œê°í™”ë¥¼ ì ì ˆí•œ ìœ„ì¹˜ì— ì‚½ì…
            logger.info(f"ğŸ¨ {len(visual_sections)}ê°œì˜ ì‹œê°í™”ë¥¼ ë°°ì¹˜ ì¤‘...")
            final_sections = self._merge_visualizations(structured_sections, visual_sections)

            # 3. ì œëª©ê³¼ ìš”ì•½ ì¶”ì¶œ
            title = self._extract_title(summary)
            brief_summary = self._create_brief_summary(summary)

            # 4. í†µê³„ ì •ë³´ ìƒì„±
            statistics = ReportStatistics(
                total_sections=len(final_sections),
                text_sections=len([s for s in final_sections if s.get("type") == "text"]),
                visualizations=len([s for s in final_sections if s.get("type") == "visualization"])
            )

            # 5. ì²˜ë¦¬ ì •ë³´ ìƒì„±
            process_info = ProcessInfo(
                youtube_url=youtube_url,
                caption_length=len(caption),
                summary_length=len(summary)
            )

            # 6. ìµœì¢… ë¦¬í¬íŠ¸ êµ¬ì„±
            report_result = {
                "success": True,
                "title": title,
                "summary": brief_summary,
                "sections": final_sections,
                "statistics": statistics.dict(),
                "process_info": process_info.dict(),
                "created_at": datetime.now()
            }

            logger.info(f"âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {len(final_sections)}ê°œ ì„¹ì…˜")
            return {**state, "report_result": report_result}

        except Exception as e:
            error_msg = f"ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}"
            logger.error(error_msg)
            return {**state, "report_result": self._create_error_report(error_msg)}

    def _structure_summary(self, summary: str) -> List[Dict[str, Any]]:
        """ìš”ì•½ì„ ìƒˆë¡œìš´ ë³´ê³ ì„œ êµ¬ì¡°ì— ë§ê²Œ ì„¹ì…˜í™”"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ì£¼ì–´ì§„ ë³´ê³ ì„œë¥¼ ìƒˆë¡œìš´ êµ¬ì¡°ì— ë§ê²Œ ì„¹ì…˜ìœ¼ë¡œ êµ¬ì¡°í™”í•´ì£¼ì„¸ìš”.

**ìƒˆë¡œìš´ ë³´ê³ ì„œ êµ¬ì¡°:**
1. **ì˜ìƒ í•µì‹¬ ìš”ì•½** - ë¬¸ì„œ ìµœìƒë‹¨ì˜ 3-4ì¤„ ì••ì¶• ìš”ì•½
2. **ê°œìš”** - ì„œìˆ í˜• ê°œìš” (150-200ì)
3. **ì£¼ìš” ë‚´ìš© ë¶„ì„** - 3ê°œ ì´ìƒì˜ ì„¸ë¶€ ì„¹ì…˜
4. **í•µì‹¬ ì¸ì‚¬ì´íŠ¸** - ë„ì¶œëœ ì‹œì‚¬ì 
5. **ê²°ë¡  ë° ì œì–¸** - ì¢…í•© ë° ì œì•ˆ
6. **ë¶€ë¡** - ì¸ìš©êµ¬ ë° ì°¸ê³ ìë£Œ

**êµ¬ì¡°í™” ì›ì¹™:**
- ë§ˆí¬ë‹¤ìš´ í—¤ë”ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¹ì…˜ êµ¬ë¶„
- ê° ì„¹ì…˜ì˜ ì—­í• ê³¼ ë‚´ìš©ì„ ì •í™•íˆ ë¶„ë¥˜
- ì˜ìƒ í•µì‹¬ ìš”ì•½ì€ ë³„ë„ ì‹ë³„
- ì£¼ìš” ë‚´ìš© ë¶„ì„ì˜ í•˜ìœ„ ì„¹ì…˜ë“¤ë„ ê°œë³„ ì„¹ì…˜ìœ¼ë¡œ ì²˜ë¦¬

**ì‘ë‹µ í˜•ì‹ (JSON):**
{
  "sections": [
    {
      "id": "executive_summary",
      "title": "ì˜ìƒ í•µì‹¬ ìš”ì•½",
      "type": "text",
      "content": "ì••ì¶•ì  ìš”ì•½ ë‚´ìš©",
      "level": 0,
      "section_type": "executive_summary",
      "keywords": ["í•µì‹¬í‚¤ì›Œë“œë“¤"]
    },
    {
      "id": "overview",
      "title": "ê°œìš”",
      "type": "text",
      "content": "ì„œìˆ í˜• ê°œìš” ë‚´ìš©",
      "level": 1,
      "section_type": "overview",
      "keywords": ["ê´€ë ¨í‚¤ì›Œë“œë“¤"]
    },
    {
      "id": "analysis_1",
      "title": "ë¶„ì„ ì„¹ì…˜ ì œëª©",
      "type": "text",
      "content": "ìƒì„¸ ë¶„ì„ ë‚´ìš©",
      "level": 2,
      "section_type": "main_analysis",
      "keywords": ["ë¶„ì„í‚¤ì›Œë“œë“¤"]
    }
  ]
}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""),
            ("human", "{summary}")
        ])

        try:
            response = self.llm.invoke(prompt.format_messages(summary=summary))
            content = response.content.strip()

            # JSON ì¶”ì¶œ
            start_idx = content.find('{')
            end_idx = content.rfind('}')

            if start_idx != -1 and end_idx != -1:
                json_str = content[start_idx:end_idx + 1]
                result = json.loads(json_str)
                return result.get('sections', [])
            else:
                # í´ë°±: ë§ˆí¬ë‹¤ìš´ í—¤ë” ê¸°ë°˜ íŒŒì‹±
                return self._parse_markdown_sections(summary)

        except Exception as e:
            logger.error(f"ì„¹ì…˜ êµ¬ì¡°í™” ì˜¤ë¥˜: {e}")
            return self._parse_markdown_sections(summary)

    def _parse_markdown_sections(self, summary: str) -> List[Dict[str, Any]]:
        """ë§ˆí¬ë‹¤ìš´ í—¤ë”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë³´ê³ ì„œ êµ¬ì¡°ë¡œ ì„¹ì…˜ íŒŒì‹± (í´ë°±)"""
        lines = summary.split('\n')
        sections = []
        current_section = None
        section_counter = 0
        executive_summary_found = False

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # ì˜ìƒ í•µì‹¬ ìš”ì•½ ê°ì§€ (ë¬¸ì„œ ìµœìƒë‹¨ì˜ **ë¡œ ì‹œì‘í•˜ëŠ” ë¶€ë¶„)
            if line.startswith('**ì˜ìƒ í•µì‹¬ ìš”ì•½**') and not executive_summary_found:
                if current_section and current_section['content'].strip():
                    sections.append(current_section)
                
                section_counter += 1
                current_section = {
                    "id": "executive_summary",
                    "title": "ì˜ìƒ í•µì‹¬ ìš”ì•½",
                    "type": "text",
                    "content": "",
                    "level": 0,
                    "section_type": "executive_summary",
                    "keywords": []
                }
                executive_summary_found = True
                continue

            # í—¤ë” ê°ì§€
            elif line.startswith('#'):
                # ì´ì „ ì„¹ì…˜ ì €ì¥
                if current_section and current_section['content'].strip():
                    sections.append(current_section)

                # ìƒˆ ì„¹ì…˜ ì‹œì‘
                section_counter += 1
                level = len(line) - len(line.lstrip('#'))
                title = line.lstrip('#').strip()
                
                # ì„¹ì…˜ íƒ€ì… ê²°ì •
                section_type = "text"
                if "ê°œìš”" in title:
                    section_type = "overview"
                elif "ì£¼ìš” ë‚´ìš©" in title or "ë¶„ì„" in title:
                    section_type = "main_analysis"
                elif "ì¸ì‚¬ì´íŠ¸" in title:
                    section_type = "insights"
                elif "ê²°ë¡ " in title or "ì œì–¸" in title:
                    section_type = "conclusion"
                elif "ë¶€ë¡" in title:
                    section_type = "appendix"

                current_section = {
                    "id": f"section_{section_counter}",
                    "title": title,
                    "type": "text",
                    "content": "",
                    "level": min(level, 3),
                    "section_type": section_type,
                    "keywords": []
                }
            elif current_section:
                # ë‚´ìš© ì¶”ê°€
                if current_section['content']:
                    current_section['content'] += '\n'
                current_section['content'] += line

        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
        if current_section and current_section['content'].strip():
            sections.append(current_section)

        # ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ êµ¬ì¡° ìƒì„±
        if not sections:
            sections.append({
                "id": "overview",
                "title": "ê°œìš”",
                "type": "text",
                "content": summary,
                "level": 1,
                "section_type": "overview",
                "keywords": []
            })

        return sections

    def _merge_visualizations(self, text_sections: List[Dict], visual_sections: List[Dict]) -> List[Dict]:
        """í…ìŠ¤íŠ¸ ì„¹ì…˜ê³¼ ì‹œê°í™”ë¥¼ ì ì ˆíˆ ë³‘í•©"""
        if not visual_sections:
            return text_sections

        # ì‹œê°í™”ë¥¼ ìœ„ì¹˜ ì •ë³´ë¡œ ì •ë ¬
        sorted_visuals = sorted(
            visual_sections,
            key=lambda x: x.get('position', {}).get('after_paragraph', 999)
        )

        final_sections = []
        visual_index = 0

        for i, text_section in enumerate(text_sections):
            # í…ìŠ¤íŠ¸ ì„¹ì…˜ ì¶”ê°€
            final_sections.append(text_section)

            # ì´ ìœ„ì¹˜ì— ì‚½ì…í•  ì‹œê°í™” í™•ì¸
            while (visual_index < len(sorted_visuals) and
                   sorted_visuals[visual_index].get('position', {}).get('after_paragraph', 999) <= i):

                visual = sorted_visuals[visual_index]

                # ì‹œê°í™” ë°ì´í„° ë³€í™˜
                viz_data = None
                if visual.get('data'):
                    viz_data = VisualizationData(**visual['data'])

                final_sections.append({
                    "id": f"visual_{visual_index + 1}",
                    "title": visual.get('title', 'ì‹œê°í™”'),
                    "type": "visualization",
                    "visualization_type": visual.get('visualization_type'),
                    "data": viz_data.dict() if viz_data else None,
                    "insight": visual.get('insight', ''),
                    "purpose": visual.get('purpose', ''),
                    "user_benefit": visual.get('user_benefit', '')
                })
                visual_index += 1

        # ë‚¨ì€ ì‹œê°í™” ì¶”ê°€
        while visual_index < len(sorted_visuals):
            visual = sorted_visuals[visual_index]

            viz_data = None
            if visual.get('data'):
                viz_data = VisualizationData(**visual['data'])

            final_sections.append({
                "id": f"visual_{visual_index + 1}",
                "title": visual.get('title', 'ì‹œê°í™”'),
                "type": "visualization",
                "visualization_type": visual.get('visualization_type'),
                "data": viz_data.dict() if viz_data else None,
                "insight": visual.get('insight', ''),
                "purpose": visual.get('purpose', ''),
                "user_benefit": visual.get('user_benefit', '')
            })
            visual_index += 1

        return final_sections

    def _extract_title(self, summary: str) -> str:
        """ìš”ì•½ì—ì„œ ì ì ˆí•œ ì œëª© ì¶”ì¶œ"""
        lines = summary.split('\n')

        # ì²« ë²ˆì§¸ í—¤ë”ë¥¼ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
        for line in lines:
            line = line.strip()
            if line.startswith('#'):
                title = line.lstrip('#').strip()
                if title and len(title) < 100:
                    return title

        # ì²« ë¬¸ì¥ì„ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
        first_line = lines[0].strip() if lines else "YouTube ì˜ìƒ ë¶„ì„"
        if len(first_line) > 100:
            first_line = first_line[:97] + "..."

        return first_line or "YouTube ì˜ìƒ ë¶„ì„"

    def _create_brief_summary(self, summary: str) -> str:
        """ì „ì²´ ìš”ì•½ì˜ ê°„ë‹¨í•œ ìš”ì•½ ìƒì„± (2-3ë¬¸ì¥)"""
        # ê°œìš” ì„¹ì…˜ ì°¾ê¸°
        lines = summary.split('\n')
        overview_content = ""

        in_overview = False
        for line in lines:
            line = line.strip()
            if 'ê°œìš”' in line and line.startswith('#'):
                in_overview = True
                continue
            elif line.startswith('#') and in_overview:
                break
            elif in_overview and line:
                overview_content += line + ' '

        if overview_content:
            # ì²« 2-3ë¬¸ì¥ë§Œ ì¶”ì¶œ
            sentences = overview_content.split('.')
            brief = '. '.join(sentences[:3]).strip()
            if brief and not brief.endswith('.'):
                brief += '.'
            return brief

        # í´ë°±: ì „ì²´ ìš”ì•½ì˜ ì²« ë¶€ë¶„
        sentences = summary.replace('\n', ' ').split('.')
        important_sentences = []

        for sentence in sentences[:5]:
            sentence = sentence.strip()
            if len(sentence) > 20 and len(sentence) < 200:
                important_sentences.append(sentence)
                if len(important_sentences) >= 2:
                    break

        brief = '. '.join(important_sentences)
        if brief and not brief.endswith('.'):
            brief += '.'

        return brief or "YouTube ì˜ìƒì˜ í•µì‹¬ ë‚´ìš©ì„ ë¶„ì„í•œ ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤."

    def _create_error_report(self, error_message: str) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        return {
            "success": False,
            "title": "ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨",
            "summary": f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_message}",
            "sections": [
                {
                    "id": "error_section",
                    "title": "ì˜¤ë¥˜ ì •ë³´",
                    "type": "text",
                    "content": f"ì£„ì†¡í•©ë‹ˆë‹¤. ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ë‹¤ìŒê³¼ ê°™ì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n\n{error_message}\n\në‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê±°ë‚˜, ë‹¤ë¥¸ ì˜ìƒìœ¼ë¡œ ì‹œë„í•´ ë³´ì„¸ìš”.",
                    "level": 1,
                    "keywords": ["ì˜¤ë¥˜", "ì‹¤íŒ¨"]
                }
            ],
            "statistics": {
                "total_sections": 1,
                "text_sections": 1,
                "visualizations": 0
            },
            "process_info": {
                "youtube_url": "",
                "caption_length": 0,
                "summary_length": 0,
                "error": error_message
            },
            "created_at": datetime.now()
        }