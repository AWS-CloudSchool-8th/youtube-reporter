# app/agents/visual_agent.py
import json
import boto3
from typing import Dict, List, Any, Optional
from langchain_aws import ChatBedrock
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import Runnable
from ..core.config import settings
from ..utils.logger import get_logger

logger = get_logger(__name__)


class VisualAgent(Runnable):
    """ìŠ¤ë§ˆíŠ¸ ì‹œê°í™” ìƒì„± ì—ì´ì „íŠ¸"""

    def __init__(self):
        self.llm = ChatBedrock(
            client=boto3.client("bedrock-runtime", region_name=settings.aws_region),
            model_id=settings.bedrock_model_id,
            model_kwargs={"temperature": 0.7, "max_tokens": 4096}
        )

    def invoke(self, state: Dict[str, Any], config=None) -> Dict[str, Any]:
        """ìŠ¤ë§ˆíŠ¸ ì‹œê°í™” ìƒì„±"""
        summary = state.get("summary", "")

        if not summary or "[ì˜¤ë¥˜]" in summary:
            logger.warning("ìœ íš¨í•œ ìš”ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {**state, "visual_sections": []}

        try:
            logger.info("ğŸ¨ ìŠ¤ë§ˆíŠ¸ ì‹œê°í™” ë¶„ì„ ì‹œì‘...")

            # 1ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
            context = self._analyze_context(summary)
            if not context or "error" in context:
                logger.error(f"ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {context}")
                return {**state, "visual_sections": []}

            # 2ë‹¨ê³„: ì‹œê°í™” ê¸°íšŒë³„ë¡œ ìµœì ì˜ ì‹œê°í™” ìƒì„±
            opportunities = context.get('visualization_opportunities', [])
            logger.info(f"ğŸ¯ {len(opportunities)}ê°œì˜ ì‹œê°í™” ê¸°íšŒ ë°œê²¬")

            visual_sections = []
            for i, opportunity in enumerate(opportunities):
                logger.info(f"ğŸ¨ ì‹œê°í™” {i + 1}/{len(opportunities)} ìƒì„± ì¤‘...")

                visualization = self._generate_smart_visualization(context, opportunity)
                if visualization and "error" not in visualization:
                    # ì ì ˆí•œ ìœ„ì¹˜ ì°¾ê¸°
                    position = self._find_best_position(summary, opportunity)

                    visual_section = {
                        "position": position,
                        "title": visualization.get('title', opportunity.get('content', 'ì‹œê°í™”')[:50]),
                        "visualization_type": visualization.get('type'),
                        "data": self._standardize_visualization_data(visualization),
                        "insight": visualization.get('insight', ''),
                        "purpose": opportunity.get('purpose', ''),
                        "user_benefit": opportunity.get('user_benefit', '')
                    }
                    visual_sections.append(visual_section)
                    logger.info(f"âœ… ì‹œê°í™” ìƒì„± ì„±ê³µ: {visualization.get('type')}")
                else:
                    logger.warning(f"âš ï¸ ì‹œê°í™” {i + 1} ìƒì„± ì‹¤íŒ¨")

            logger.info(f"ğŸ“Š ì´ {len(visual_sections)}ê°œì˜ ì‹œê°í™” ìƒì„± ì™„ë£Œ")
            return {**state, "visual_sections": visual_sections}

        except Exception as e:
            error_msg = f"ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
            logger.error(error_msg)
            return {**state, "visual_sections": []}

    def _analyze_context(self, summary: str) -> Dict[str, Any]:
        """ìš”ì•½ ë‚´ìš©ì˜ ë§¥ë½ì„ ê¹Šì´ ë¶„ì„"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œê°í™”ê°€ í•„ìš”í•œ ë¶€ë¶„ì„ ì°¾ì•„ë‚´ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ìš”ì•½ì„ ë¶„ì„í•˜ì—¬ ë…ìì˜ ì´í•´ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ì‹œê°í™” ê¸°íšŒë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

**ë¶„ì„ ê¸°ì¤€:**
1. **ë³µì¡í•œ ê°œë…**: í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œëŠ” ì´í•´í•˜ê¸° ì–´ë ¤ìš´ ì¶”ìƒì  ê°œë…
2. **í”„ë¡œì„¸ìŠ¤/ì ˆì°¨**: ë‹¨ê³„ë³„ ê³¼ì •ì´ë‚˜ íë¦„
3. **ë¹„êµ/ëŒ€ì¡°**: ì—¬ëŸ¬ í•­ëª© ê°„ì˜ ì°¨ì´ì ì´ë‚˜ ìœ ì‚¬ì 
4. **ë°ì´í„°/ìˆ˜ì¹˜**: í†µê³„, ë¹„ìœ¨, ì¶”ì„¸ ë“± ìˆ˜ì¹˜ ì •ë³´
5. **ê´€ê³„/êµ¬ì¡°**: ìš”ì†Œë“¤ ê°„ì˜ ì—°ê²°ì´ë‚˜ ê³„ì¸µ êµ¬ì¡°
6. **ì‹œê°„ íë¦„**: ì‹œê°„ì— ë”°ë¥¸ ë³€í™”ë‚˜ íƒ€ì„ë¼ì¸

**ì¤‘ìš”**: ì‹œê°í™”ëŠ” "ìˆìœ¼ë©´ ì¢‹ì€" ê²ƒì´ ì•„ë‹ˆë¼ "ë°˜ë“œì‹œ í•„ìš”í•œ" ê²½ìš°ì—ë§Œ ì œì•ˆí•˜ì„¸ìš”.
ê° ì‹œê°í™”ëŠ” ëª…í™•í•œ ëª©ì ê³¼ ì‚¬ìš©ì ê°€ì¹˜ë¥¼ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.

**ì‘ë‹µ í˜•ì‹ (JSON):**
{
  "main_topic": "ì „ì²´ ì£¼ì œ",
  "key_concepts": ["í•µì‹¬ê°œë…1", "í•µì‹¬ê°œë…2", "í•µì‹¬ê°œë…3"],
  "content_structure": {
    "has_process": true/false,
    "has_comparison": true/false,
    "has_data": true/false,
    "has_timeline": true/false,
    "has_hierarchy": true/false
  },
  "visualization_opportunities": [
    {
      "content": "ì‹œê°í™”í•  êµ¬ì²´ì  ë‚´ìš©",
      "location_hint": "ìš”ì•½ ë‚´ ëŒ€ëµì  ìœ„ì¹˜ (beginning/middle/end)",
      "purpose": "overview|detail|comparison|process|data|timeline|structure",
      "why_necessary": "ì™œ ì´ ì‹œê°í™”ê°€ í•„ìˆ˜ì ì¸ì§€",
      "user_benefit": "ë…ìê°€ ì–»ì„ êµ¬ì²´ì  ì´ìµ",
      "suggested_type": "chart|diagram|table|mindmap|timeline|flowchart",
      "key_elements": ["í¬í•¨í•´ì•¼ í•  í•µì‹¬ ìš”ì†Œë“¤"]
    }
  ]
}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""),
            ("human", "{summary}")
        ])

        try:
            response = self.llm.invoke(prompt.format_messages(summary=summary))
            content = response.content.strip()

            # JSON ì¶”ì¶œ
            start_idx = content.find('{')
            end_idx = content.rfind('}')

            if start_idx != -1 and end_idx != -1:
                json_str = content[start_idx:end_idx + 1]
                return json.loads(json_str)
            else:
                return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨"}

        except Exception as e:
            logger.error(f"ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def _generate_smart_visualization(self, context: Dict[str, Any], opportunity: Dict[str, Any]) -> Dict[str, Any]:
        """ì£¼ì–´ì§„ ê¸°íšŒì— ëŒ€í•´ ìµœì ì˜ ì‹œê°í™” ìƒì„±"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë‚´ìš©ì„ ê°€ì¥ íš¨ê³¼ì ìœ¼ë¡œ ì‹œê°í™”í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ìƒí™©:**
- ì£¼ì œ: {main_topic}
- ì‹œê°í™” ëª©ì : {purpose}
- í•„ìš”í•œ ì´ìœ : {why_necessary}
- ì‚¬ìš©ì ì´ìµ: {user_benefit}

**ì‹œê°í™”í•  ë‚´ìš©:**
{content}

**í•µì‹¬ ìš”ì†Œ:**
{key_elements}

**ë‹¹ì‹ ì˜ ì„ë¬´:**
1. ì´ ë‚´ìš©ì„ ê°€ì¥ ëª…í™•í•˜ê³  ì§ê´€ì ìœ¼ë¡œ í‘œí˜„í•  ì‹œê°í™” ë°©ë²• ê²°ì •
2. ì‹¤ì œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê±°ë‚˜ í•©ë¦¬ì ìœ¼ë¡œ ìƒì„±
3. êµ¬ì²´ì ì¸ ì‹œê°í™” ì„¤ì • ì œê³µ

**ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œê°í™” ìœ í˜•:**

1. **Chart.js ì°¨íŠ¸**
   - bar: í•­ëª© ê°„ ë¹„êµ, ìˆœìœ„
   - line: ì‹œê°„ì— ë”°ë¥¸ ë³€í™”, ì¶”ì„¸
   - pie/doughnut: êµ¬ì„± ë¹„ìœ¨, ì ìœ ìœ¨
   - radar: ë‹¤ì°¨ì› ë¹„êµ
   - scatter: ìƒê´€ê´€ê³„, ë¶„í¬

2. **Mermaid ë‹¤ì´ì–´ê·¸ë¨**
   - flowchart: í”„ë¡œì„¸ìŠ¤, ì˜ì‚¬ê²°ì • íë¦„
   - timeline: ì‹œê°„ ìˆœì„œ, ì—­ì‚¬ì  ì‚¬ê±´
   - mindmap: ê°œë… êµ¬ì¡°, ë¶„ë¥˜ ì²´ê³„
   - gantt: í”„ë¡œì íŠ¸ ì¼ì •

3. **HTML í…Œì´ë¸”**
   - ì •í™•í•œ ìˆ˜ì¹˜ ë¹„êµ
   - ë‹¤ì–‘í•œ ì†ì„±ì„ ê°€ì§„ í•­ëª©ë“¤
   - ì²´í¬ë¦¬ìŠ¤íŠ¸, ê¸°ëŠ¥ ë¹„êµí‘œ

**ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜):**

**ì˜µì…˜ 1 - Chart.js ì°¨íŠ¸:**
{
  "type": "chart",
  "library": "chartjs",
  "title": "ëª…í™•í•œ ì œëª©",
  "chart_type": "bar|line|pie|radar|scatter",
  "data": {
    "labels": ["ë ˆì´ë¸”1", "ë ˆì´ë¸”2", ...],
    "datasets": [
      {
        "label": "ë°ì´í„°ì…‹ ì´ë¦„",
        "data": [ìˆ«ì1, ìˆ«ì2, ...],
        "backgroundColor": ["ìƒ‰ìƒ1", "ìƒ‰ìƒ2", ...]
      }
    ]
  },
  "options": {
    "responsive": true,
    "plugins": {
      "title": { "display": true, "text": "ì°¨íŠ¸ ì œëª©" },
      "legend": { "position": "top" }
    }
  },
  "insight": "ì´ ì°¨íŠ¸ê°€ ë³´ì—¬ì£¼ëŠ” í•µì‹¬ ì¸ì‚¬ì´íŠ¸"
}

**ì˜µì…˜ 2 - Mermaid ë‹¤ì´ì–´ê·¸ë¨:**
{
  "type": "diagram",
  "library": "mermaid",
  "title": "ëª…í™•í•œ ì œëª©",
  "diagram_type": "flowchart|timeline|mindmap",
  "code": "Mermaid ë‹¤ì´ì–´ê·¸ë¨ ì½”ë“œ",
  "insight": "ì´ ë‹¤ì´ì–´ê·¸ë¨ì´ ì„¤ëª…í•˜ëŠ” í•µì‹¬ ë‚´ìš©"
}

**ì˜µì…˜ 3 - HTML í…Œì´ë¸”:**
{
  "type": "table",
  "title": "ëª…í™•í•œ ì œëª©",
  "headers": ["ì—´1", "ì—´2", "ì—´3"],
  "rows": [
    ["ë°ì´í„°1-1", "ë°ì´í„°1-2", "ë°ì´í„°1-3"],
    ["ë°ì´í„°2-1", "ë°ì´í„°2-2", "ë°ì´í„°2-3"]
  ],
  "styling": {
    "highlight_column": 0,
    "sortable": true
  },
  "insight": "ì´ í‘œê°€ ë³´ì—¬ì£¼ëŠ” í•µì‹¬ ì •ë³´"
}

**ì¤‘ìš” ì§€ì¹¨:**
- ë‚´ìš©ì—ì„œ ì‹¤ì œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”
- ë°ì´í„°ê°€ ì—†ë‹¤ë©´ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë¦¬ì ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”
- ìƒ‰ìƒì€ ì˜ë¯¸ë¥¼ ë‹´ì•„ ì„ íƒí•˜ì„¸ìš” (ì¦ê°€=ë…¹ìƒ‰, ê°ì†Œ=ë¹¨ê°• ë“±)
- ì œëª©ê³¼ ë ˆì´ë¸”ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ
- insightëŠ” ë‹¨ìˆœ ì„¤ëª…ì´ ì•„ë‹Œ "ë°œê²¬"ì´ì–´ì•¼ í•©ë‹ˆë‹¤

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""),
            ("human", "ì‹œê°í™”ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        ])

        try:
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í¬ë§·íŒ…
            formatted_prompt = prompt.format_messages(
                main_topic=context.get('main_topic', ''),
                purpose=opportunity.get('purpose', ''),
                why_necessary=opportunity.get('why_necessary', ''),
                user_benefit=opportunity.get('user_benefit', ''),
                content=opportunity.get('content', ''),
                key_elements=', '.join(opportunity.get('key_elements', []))
            )

            response = self.llm.invoke(formatted_prompt)
            content = response.content.strip()

            # JSON ì¶”ì¶œ
            start_idx = content.find('{')
            end_idx = content.rfind('}')

            if start_idx != -1 and end_idx != -1:
                json_str = content[start_idx:end_idx + 1]
                return json.loads(json_str)
            else:
                return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨"}

        except Exception as e:
            logger.error(f"ì‹œê°í™” ìƒì„± ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def _find_best_position(self, summary: str, opportunity: Dict[str, Any]) -> Dict[str, Any]:
        """ìš”ì•½ ë‚´ì—ì„œ ì‹œê°í™”ë¥¼ ë°°ì¹˜í•  ìµœì ì˜ ìœ„ì¹˜ ì°¾ê¸°"""
        content = opportunity.get('content', '')
        location_hint = opportunity.get('location_hint', 'middle')

        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ìœ„ì¹˜ ê²°ì •
        paragraphs = summary.split('\n\n')
        total_paragraphs = len(paragraphs)

        # ê´€ë ¨ í‚¤ì›Œë“œ ì°¾ê¸°
        keywords = content.lower().split()[:5]  # ì²˜ìŒ 5ê°œ ë‹¨ì–´

        best_position = 0
        max_score = 0

        for i, paragraph in enumerate(paragraphs):
            paragraph_lower = paragraph.lower()
            score = sum(1 for keyword in keywords if keyword in paragraph_lower)

            # ìœ„ì¹˜ íŒíŠ¸ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
            if location_hint == "beginning" and i < total_paragraphs // 3:
                score += 2
            elif location_hint == "middle" and total_paragraphs // 3 <= i < 2 * total_paragraphs // 3:
                score += 2
            elif location_hint == "end" and i >= 2 * total_paragraphs // 3:
                score += 2

            if score > max_score:
                max_score = score
                best_position = i

        return {
            "after_paragraph": best_position,
            "relevance_score": max_score
        }

    def _standardize_visualization_data(self, visualization: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¤ì–‘í•œ ì‹œê°í™” í˜•ì‹ì„ í‘œì¤€í™”"""
        viz_type = visualization.get('type')

        if viz_type == 'chart':
            return {
                "type": "chart",
                "library": visualization.get('library', 'chartjs'),
                "config": {
                    "type": visualization.get('chart_type', 'bar'),
                    "data": visualization.get('data', {}),
                    "options": visualization.get('options', {})
                }
            }

        elif viz_type == 'diagram':
            return {
                "type": "diagram",
                "library": visualization.get('library', 'mermaid'),
                "diagram_type": visualization.get('diagram_type', 'flowchart'),
                "code": visualization.get('code', '')
            }

        elif viz_type == 'table':
            return {
                "type": "table",
                "headers": visualization.get('headers', []),
                "rows": visualization.get('rows', []),
                "styling": visualization.get('styling', {})
            }

        else:
            return visualization